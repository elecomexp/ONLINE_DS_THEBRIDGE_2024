{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz-Nmm6ukHaA"
   },
   "source": [
    "![imagen](data/foto1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LORptjAQkHaB"
   },
   "source": [
    "### CAPAS DE PREPROCESADO DE KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8LtIhgukHaB"
   },
   "source": [
    "Igual que sklearn tenemos sus \"transformers\" y difernentes funciones para poder procesar los datos, para luego, si queremos incluirlos en un pipeline, en Keras existen \"capas\" de preprocesamiento que podemos incluir en el modelo de forma análoga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPtuW9ftkHaB"
   },
   "source": [
    "### El problema y el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67wZ3fCFkHaC"
   },
   "source": [
    "En este caso nuestro problema será clasificar una serie de fármacos a partir de features numéricas y features de texto, que tendremos que convertir para poder utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDOLSlPNkHaC"
   },
   "source": [
    "Vamos a trabajar con un dataset que hemos empleado antes con reviews de medicinas, pero en el que no utilizamos los campos de texto. Sobre él vamos a hacer el preprocesado usando esas capas equivalentes a lo que ya hemos empleado con sklearn. Eso nos permitirá introducir las capas de Embedding y de ahí a revisar un ejemplo de clasificación con texto en lenguaje natural que ahora haremos con modelos DL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9GCwcI_kHaC"
   },
   "source": [
    "Primero, las importaciones y cargar el dataset, y echar un \"vistazo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvfwwsYCkHaC"
   },
   "outputs": [],
   "source": [
    "import random as rm\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "9-_Ypv0QkHaD",
    "outputId": "0bbe290a-f00f-4d43-bfcb-c0dee87bb8be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough, hypotension , proteinuria, impotence , ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "      <td>318440</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "      <td>888949</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>Heavier bleeding and clotting than normal.</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "      <td>264077</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>Constipation, dry mouth and some mild dizzines...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "      <td>542110</td>\n",
       "      <td>602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>I felt extremely drugged and dopey.  Could not...</td>\n",
       "      <td>See above</td>\n",
       "      <td>83761</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        urlDrugName  rating         effectiveness          sideEffects  \\\n",
       "0         enalapril       4      Highly Effective    Mild Side Effects   \n",
       "1  ortho-tri-cyclen       1      Highly Effective  Severe Side Effects   \n",
       "2           ponstel      10      Highly Effective      No Side Effects   \n",
       "3          prilosec       3  Marginally Effective    Mild Side Effects   \n",
       "4            lyrica       2  Marginally Effective  Severe Side Effects   \n",
       "\n",
       "                                condition  \\\n",
       "0  management of congestive heart failure   \n",
       "1                        birth prevention   \n",
       "2                        menstrual cramps   \n",
       "3                             acid reflux   \n",
       "4                            fibromyalgia   \n",
       "\n",
       "                                      benefitsReview  \\\n",
       "0  slowed the progression of left ventricular dys...   \n",
       "1  Although this type of birth control has more c...   \n",
       "2  I was used to having cramps so badly that they...   \n",
       "3  The acid reflux went away for a few months aft...   \n",
       "4  I think that the Lyrica was starting to help w...   \n",
       "\n",
       "                                   sideEffectsReview  \\\n",
       "0  cough, hypotension , proteinuria, impotence , ...   \n",
       "1  Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
       "2         Heavier bleeding and clotting than normal.   \n",
       "3  Constipation, dry mouth and some mild dizzines...   \n",
       "4  I felt extremely drugged and dopey.  Could not...   \n",
       "\n",
       "                                      commentsReview   Sales  Production  \n",
       "0  monitor blood pressure , weight and asses for ...  318440       398.0  \n",
       "1  I Hate This Birth Control, I Would Not Suggest...  888949       909.0  \n",
       "2  I took 2 pills at the onset of my menstrual cr...  264077       465.0  \n",
       "3  I was given Prilosec prescription at a dose of...  542110       602.0  \n",
       "4                                          See above   83761       124.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/pharma_full.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsgKnoXSkHaD",
    "outputId": "1c50e0ef-4d28-4ded-8e09-d131e0b881b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3107 entries, 0 to 3106\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   urlDrugName        3107 non-null   object \n",
      " 1   rating             3107 non-null   int64  \n",
      " 2   effectiveness      3107 non-null   object \n",
      " 3   sideEffects        3107 non-null   object \n",
      " 4   condition          3106 non-null   object \n",
      " 5   benefitsReview     3089 non-null   object \n",
      " 6   sideEffectsReview  3032 non-null   object \n",
      " 7   commentsReview     3095 non-null   object \n",
      " 8   Sales              3107 non-null   int64  \n",
      " 9   Production         3107 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 242.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "si_TBOULkHaE"
   },
   "source": [
    "Las prepararemos un poco para que podamos emplear todos los tipos de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUMZPgBVkHaE"
   },
   "source": [
    "Los missings seguiremos tratándolos, por ahora, a parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E-Zb9NUPkHaE"
   },
   "outputs": [],
   "source": [
    "df_clean = df.fillna(\"No Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3hv4I18kHaE",
    "outputId": "749739e8-af52-4bad-da66-91d4048a65be",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3107 entries, 0 to 3106\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   urlDrugName        3107 non-null   object \n",
      " 1   rating             3107 non-null   int64  \n",
      " 2   effectiveness      3107 non-null   object \n",
      " 3   sideEffects        3107 non-null   object \n",
      " 4   condition          3107 non-null   object \n",
      " 5   benefitsReview     3107 non-null   object \n",
      " 6   sideEffectsReview  3107 non-null   object \n",
      " 7   commentsReview     3107 non-null   object \n",
      " 8   Sales              3107 non-null   int64  \n",
      " 9   Production         3107 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 242.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEEsjCcHkHaE"
   },
   "source": [
    "Claramente el target es \"rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RuuoKOU_kHaE"
   },
   "outputs": [],
   "source": [
    "target = \"rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0tqkfIdkHaE"
   },
   "source": [
    "### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p8o5CDwKkHaF"
   },
   "outputs": [],
   "source": [
    "train_set, test_set  = train_test_split(df_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OY9DTaM5kHaF",
    "outputId": "baa92a4b-ae67-419d-c159-fb97bf1f5ab8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsAGFYpdkHaF",
    "outputId": "a8e62ba2-116d-410c-b9e9-e2d4f675d536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOFjJ9SqkHaF"
   },
   "source": [
    "### Mini-EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOvj_bKQkHaF"
   },
   "source": [
    "Del miniEDA sólo vamos a hacer el análisis del target, nos vamos a quedar y a tratar todas las variables como features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "wyFUtuJwkHaF",
    "outputId": "b7a15769-fd83-4c7f-a3c2-421be40cda08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "10    591\n",
       "8     464\n",
       "9     370\n",
       "7     267\n",
       "1     243\n",
       "5     132\n",
       "3     123\n",
       "6     119\n",
       "4      89\n",
       "2      87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCJ_jrkAkHaG"
   },
   "source": [
    "Es un dataset `desbalanceado` en el target. Luego veremos como equilibrarlo dentro de lo posible sin aplicar SMOTE ni undersampling (con campos con texto además tiene aún menos utilidad, en general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anmGtRKIkHaG"
   },
   "source": [
    "Como ya sabrás a keras le gusta que las clases empiecen en cero así que lo tratamos rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "v1OrkdVwkHaG"
   },
   "outputs": [],
   "source": [
    "# forzar que las clases empiecen en cero (porque keras lo necesita)\n",
    "train_set[target] = train_set[target] - 1\n",
    "test_set[target] = test_set[target] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SenH60TkkHaG"
   },
   "source": [
    "### Tratamiento de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6ZuopQAkHaG"
   },
   "source": [
    "Vamos a hacer lo siguiente:  \n",
    "1- Crear features nuevas (conteos de palabras por campo de texto libre)  \n",
    "2- Escalado de las features numéricas  \n",
    "3- Conversión de las categóricas  \n",
    "4- Vectorización de las features de texto  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9E_iacPkHaG"
   },
   "source": [
    "#### #1 Creación de features nuevas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvioGoxjkHaH"
   },
   "source": [
    "Existen varios campos con texto libre y en breve los vectorizaremos pero antes puede ser interesante crear una serie de features nuevas que cuenten el número aproximado de palabras que hay en cada uno de esos campos. Estos campos son básicamente lo que tienen en su nombre la palabra \"Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7swwlzvZkHaH"
   },
   "outputs": [],
   "source": [
    "# word-count\n",
    "for col in [col for col in train_set.columns if \"Review\" in col]:\n",
    "    train_set[col + \"_wc\"] = train_set[col].apply(lambda value: len(value.split()))\n",
    "    test_set[col + \"_wc\"] = test_set[col].apply(lambda value: len(value.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "SBpgkrrWkHaH",
    "outputId": "2c7af2da-7e67-4725-de0e-534e0102ffec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "      <th>benefitsReview_wc</th>\n",
       "      <th>sideEffectsReview_wc</th>\n",
       "      <th>commentsReview_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>zoloft</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>becoming a normal functioning individual. it h...</td>\n",
       "      <td>I had no real side effects unless you consider...</td>\n",
       "      <td>taken once daily.</td>\n",
       "      <td>135166</td>\n",
       "      <td>335.0</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>adipex-p</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>to lose 30 pounds</td>\n",
       "      <td>When BMI rating is over 27 its time to get tha...</td>\n",
       "      <td>jittery.. sometimes euphoric.. tired but cant ...</td>\n",
       "      <td>last results 3 months on adipex-p lost 30 poun...</td>\n",
       "      <td>739564</td>\n",
       "      <td>939.0</td>\n",
       "      <td>163</td>\n",
       "      <td>10</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>tri-luma</td>\n",
       "      <td>7</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>hyperpigmentation</td>\n",
       "      <td>lightening of acne scars</td>\n",
       "      <td>redness, dryness, breakdown of skin</td>\n",
       "      <td>this topical compound was used to reduce hyper...</td>\n",
       "      <td>683247</td>\n",
       "      <td>843.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>yasmin</td>\n",
       "      <td>2</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>birth control</td>\n",
       "      <td>There was no chance of pregancy because i lost...</td>\n",
       "      <td>no libido what so ever. My breasts hurt like n...</td>\n",
       "      <td>I was given this to prevent pregnancy and i am...</td>\n",
       "      <td>222295</td>\n",
       "      <td>282.0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>requip</td>\n",
       "      <td>7</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>restless leg syndrome</td>\n",
       "      <td>I took this medication to treat restless leg s...</td>\n",
       "      <td>I did need to take more as time went on, and I...</td>\n",
       "      <td>I took one milligram at night to treat the sym...</td>\n",
       "      <td>344748</td>\n",
       "      <td>505.0</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>zyrtec</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>atopic eczema</td>\n",
       "      <td>The drug was very effective in counteracting s...</td>\n",
       "      <td>I felt slightly tired after taking Zyrtec. How...</td>\n",
       "      <td>This is a non-prescription drug and I took it ...</td>\n",
       "      <td>156028</td>\n",
       "      <td>356.0</td>\n",
       "      <td>74</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>neurontin</td>\n",
       "      <td>0</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>all over and various type pain</td>\n",
       "      <td>No Value</td>\n",
       "      <td>Nausea, extreme sleepiness,severe headache, ji...</td>\n",
       "      <td>Day one I felt negative side effects after tak...</td>\n",
       "      <td>317886</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>wellbutrin</td>\n",
       "      <td>6</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>depression</td>\n",
       "      <td>I experienced less depression, increased libid...</td>\n",
       "      <td>I have a dry mouth and eyes. Drug has decrease...</td>\n",
       "      <td>Prescribed at 300 mg per day, have taken as mu...</td>\n",
       "      <td>556187</td>\n",
       "      <td>696.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>wellbutrin</td>\n",
       "      <td>2</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>stop smoking</td>\n",
       "      <td>The treatment was effective in reducing my \"ap...</td>\n",
       "      <td>After a while, I began to notice that NOTHING ...</td>\n",
       "      <td>I was taking the Bupropion as an aide to break...</td>\n",
       "      <td>728338</td>\n",
       "      <td>789.0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>accutane</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Extremely Severe Side Effects</td>\n",
       "      <td>cystic acne</td>\n",
       "      <td>The drug cleared my skin and even reduced some...</td>\n",
       "      <td>severe sexual side effects began about 2 month...</td>\n",
       "      <td>treatment began with two 40mg tablets twice a ...</td>\n",
       "      <td>154819</td>\n",
       "      <td>255.0</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     urlDrugName  rating           effectiveness  \\\n",
       "2686      zoloft       9        Highly Effective   \n",
       "1192    adipex-p       9        Highly Effective   \n",
       "2738    tri-luma       7    Moderately Effective   \n",
       "2780      yasmin       2        Highly Effective   \n",
       "1735      requip       7  Considerably Effective   \n",
       "...          ...     ...                     ...   \n",
       "3092      zyrtec       9        Highly Effective   \n",
       "1095   neurontin       0             Ineffective   \n",
       "1130  wellbutrin       6    Moderately Effective   \n",
       "1294  wellbutrin       2  Considerably Effective   \n",
       "860     accutane       4        Highly Effective   \n",
       "\n",
       "                        sideEffects                       condition  \\\n",
       "2686                No Side Effects                         anxiety   \n",
       "1192              Mild Side Effects               to lose 30 pounds   \n",
       "2738            Severe Side Effects               hyperpigmentation   \n",
       "2780          Moderate Side Effects                   birth control   \n",
       "1735                No Side Effects           restless leg syndrome   \n",
       "...                             ...                             ...   \n",
       "3092              Mild Side Effects                   atopic eczema   \n",
       "1095            Severe Side Effects  all over and various type pain   \n",
       "1130              Mild Side Effects                      depression   \n",
       "1294          Moderate Side Effects                    stop smoking   \n",
       "860   Extremely Severe Side Effects                     cystic acne   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "2686  becoming a normal functioning individual. it h...   \n",
       "1192  When BMI rating is over 27 its time to get tha...   \n",
       "2738                           lightening of acne scars   \n",
       "2780  There was no chance of pregancy because i lost...   \n",
       "1735  I took this medication to treat restless leg s...   \n",
       "...                                                 ...   \n",
       "3092  The drug was very effective in counteracting s...   \n",
       "1095                                           No Value   \n",
       "1130  I experienced less depression, increased libid...   \n",
       "1294  The treatment was effective in reducing my \"ap...   \n",
       "860   The drug cleared my skin and even reduced some...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "2686  I had no real side effects unless you consider...   \n",
       "1192  jittery.. sometimes euphoric.. tired but cant ...   \n",
       "2738                redness, dryness, breakdown of skin   \n",
       "2780  no libido what so ever. My breasts hurt like n...   \n",
       "1735  I did need to take more as time went on, and I...   \n",
       "...                                                 ...   \n",
       "3092  I felt slightly tired after taking Zyrtec. How...   \n",
       "1095  Nausea, extreme sleepiness,severe headache, ji...   \n",
       "1130  I have a dry mouth and eyes. Drug has decrease...   \n",
       "1294  After a while, I began to notice that NOTHING ...   \n",
       "860   severe sexual side effects began about 2 month...   \n",
       "\n",
       "                                         commentsReview   Sales  Production  \\\n",
       "2686                                  taken once daily.  135166       335.0   \n",
       "1192  last results 3 months on adipex-p lost 30 poun...  739564       939.0   \n",
       "2738  this topical compound was used to reduce hyper...  683247       843.0   \n",
       "2780  I was given this to prevent pregnancy and i am...  222295       282.0   \n",
       "1735  I took one milligram at night to treat the sym...  344748       505.0   \n",
       "...                                                 ...     ...         ...   \n",
       "3092  This is a non-prescription drug and I took it ...  156028       356.0   \n",
       "1095  Day one I felt negative side effects after tak...  317886       337.0   \n",
       "1130  Prescribed at 300 mg per day, have taken as mu...  556187       696.0   \n",
       "1294  I was taking the Bupropion as an aide to break...  728338       789.0   \n",
       "860   treatment began with two 40mg tablets twice a ...  154819       255.0   \n",
       "\n",
       "      benefitsReview_wc  sideEffectsReview_wc  commentsReview_wc  \n",
       "2686                 62                    15                  3  \n",
       "1192                163                    10                248  \n",
       "2738                  4                     5                 42  \n",
       "2780                 22                    50                 27  \n",
       "1735                 93                    69                106  \n",
       "...                 ...                   ...                ...  \n",
       "3092                 74                    54                 51  \n",
       "1095                  2                    10                120  \n",
       "1130                 15                    15                 24  \n",
       "1294                 44                   105                 92  \n",
       "860                  24                    70                145  \n",
       "\n",
       "[2485 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2rxpBhHkHaH"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEQAjLp_kHaH"
   },
   "source": [
    "#### Escalado/Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D6Svn6AkHaH"
   },
   "source": [
    "Lo primero es quedarnos con las columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0tIMZXakHaH",
    "outputId": "98ed62b2-4e13-4e43-911e-214e3d0a9ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2485 entries, 2686 to 860\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   urlDrugName           2485 non-null   object \n",
      " 1   rating                2485 non-null   int64  \n",
      " 2   effectiveness         2485 non-null   object \n",
      " 3   sideEffects           2485 non-null   object \n",
      " 4   condition             2485 non-null   object \n",
      " 5   benefitsReview        2485 non-null   object \n",
      " 6   sideEffectsReview     2485 non-null   object \n",
      " 7   commentsReview        2485 non-null   object \n",
      " 8   Sales                 2485 non-null   int64  \n",
      " 9   Production            2485 non-null   float64\n",
      " 10  benefitsReview_wc     2485 non-null   int64  \n",
      " 11  sideEffectsReview_wc  2485 non-null   int64  \n",
      " 12  commentsReview_wc     2485 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(7)\n",
      "memory usage: 271.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bF2knZlNkHaI"
   },
   "source": [
    "Son claramente las que no son tipo `object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmeY-_ZxkHaI",
    "outputId": "36fa35fd-0e64-4abe-9647-85f5275d7436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sales',\n",
       " 'Production',\n",
       " 'benefitsReview_wc',\n",
       " 'sideEffectsReview_wc',\n",
       " 'commentsReview_wc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericas = [col for col in train_set.columns if train_set[col].dtype != \"object\" and col != target]\n",
    "numericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-91uTkdkHaI"
   },
   "source": [
    "Y ahora las vamos a normalizar usando keras (en vez de usar sklearn), y además vamos a entrenar un modelo baseline solo con estas features la numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wadMCK05kHaN"
   },
   "source": [
    "### Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O-3gCgZdkHaN"
   },
   "outputs": [],
   "source": [
    "X_num = train_set[numericas].copy()\n",
    "y_num = train_set[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFjCzrQZkHaN"
   },
   "source": [
    "Probemos primero sin normalizar, creando un diccionario para compensar las clases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "02K7FU5ekHaN"
   },
   "outputs": [],
   "source": [
    "# extra code – ensures reproducibility\n",
    "tf.random.set_seed(42)  \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "earlyS = tf.keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True, monitor=\"val_acc\")\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics =[\"acc\"]\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bflyQ_n1kHaO",
    "outputId": "1623ef1d-776c-4b45-90a8-892e0725da29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.2007 - loss: 22270644224.0000 - val_acc: 0.2233 - val_loss: 2.2798\n",
      "Epoch 2/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.2711 - val_acc: 0.2233 - val_loss: 2.2572\n",
      "Epoch 3/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.2489 - val_acc: 0.2233 - val_loss: 2.2375\n",
      "Epoch 4/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.2296 - val_acc: 0.2233 - val_loss: 2.2204\n",
      "Epoch 5/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.2128 - val_acc: 0.2233 - val_loss: 2.2056\n",
      "Epoch 6/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1983 - val_acc: 0.2233 - val_loss: 2.1928\n",
      "Epoch 7/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1857 - val_acc: 0.2233 - val_loss: 2.1817\n",
      "Epoch 8/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1749 - val_acc: 0.2233 - val_loss: 2.1721\n",
      "Epoch 9/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1655 - val_acc: 0.2233 - val_loss: 2.1639\n",
      "Epoch 10/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1574 - val_acc: 0.2233 - val_loss: 2.1568\n",
      "Epoch 11/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1505 - val_acc: 0.2233 - val_loss: 2.1507\n",
      "Epoch 12/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1445 - val_acc: 0.2233 - val_loss: 2.1454\n",
      "Epoch 13/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1393 - val_acc: 0.2233 - val_loss: 2.1408\n",
      "Epoch 14/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1349 - val_acc: 0.2233 - val_loss: 2.1368\n",
      "Epoch 15/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.1310 - val_acc: 0.2233 - val_loss: 2.1333\n",
      "Epoch 16/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1276 - val_acc: 0.2233 - val_loss: 2.1302\n",
      "Epoch 17/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1247 - val_acc: 0.2233 - val_loss: 2.1276\n",
      "Epoch 18/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1222 - val_acc: 0.2233 - val_loss: 2.1253\n",
      "Epoch 19/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1200 - val_acc: 0.2233 - val_loss: 2.1232\n",
      "Epoch 20/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1181 - val_acc: 0.2233 - val_loss: 2.1214\n",
      "Epoch 21/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2419 - loss: 2.1161 - val_acc: 0.2233 - val_loss: 2.1198\n",
      "Epoch 22/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1149 - val_acc: 0.2233 - val_loss: 2.1184\n",
      "Epoch 23/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1136 - val_acc: 0.2233 - val_loss: 2.1171\n",
      "Epoch 24/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1124 - val_acc: 0.2233 - val_loss: 2.1160\n",
      "Epoch 25/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2413 - loss: 2.1115 - val_acc: 0.2233 - val_loss: 2.1150\n",
      "Epoch 26/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1105 - val_acc: 0.2233 - val_loss: 2.1141\n",
      "Epoch 27/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2414 - loss: 2.1097 - val_acc: 0.2233 - val_loss: 2.1132\n",
      "Epoch 28/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.1089 - val_acc: 0.2233 - val_loss: 2.1125\n",
      "Epoch 29/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.1083 - val_acc: 0.2233 - val_loss: 2.1118\n",
      "Epoch 30/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2413 - loss: 2.1077 - val_acc: 0.2233 - val_loss: 2.1112\n",
      "Epoch 31/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2414 - loss: 2.1072 - val_acc: 0.2233 - val_loss: 2.1107\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_num, y_num, validation_split=0.2, epochs=300, callbacks=earlyS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRY4uo-KkHaO",
    "outputId": "1289a3ee-6dc4-4c7b-b4a3-d2917968e07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2589 - loss: 2.2804 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.279801607131958, 0.24276527762413025]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set[numericas], test_set[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvjB2NaxkHaO"
   },
   "source": [
    "La cosa está fácil... Vamos con la normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JULVn5JkHaO",
    "outputId": "a03d0623-257e-4332-b0f6-baddfb7ec4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - acc: 0.1087 - loss: 2.3176 - val_acc: 0.1670 - val_loss: 2.2228\n",
      "Epoch 2/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.1637 - loss: 2.2338 - val_acc: 0.2093 - val_loss: 2.1665\n",
      "Epoch 3/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2097 - loss: 2.1734 - val_acc: 0.2113 - val_loss: 2.1263\n",
      "Epoch 4/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2393 - loss: 2.1302 - val_acc: 0.2435 - val_loss: 2.0977\n",
      "Epoch 5/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2513 - loss: 2.0995 - val_acc: 0.2676 - val_loss: 2.0769\n",
      "Epoch 6/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2577 - loss: 2.0770 - val_acc: 0.2757 - val_loss: 2.0614\n",
      "Epoch 7/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2624 - loss: 2.0600 - val_acc: 0.2736 - val_loss: 2.0493\n",
      "Epoch 8/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.2681 - loss: 2.0465 - val_acc: 0.2716 - val_loss: 2.0394\n",
      "Epoch 9/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2758 - loss: 2.0353 - val_acc: 0.2736 - val_loss: 2.0310\n",
      "Epoch 10/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2792 - loss: 2.0256 - val_acc: 0.2736 - val_loss: 2.0238\n",
      "Epoch 11/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2867 - loss: 2.0170 - val_acc: 0.2736 - val_loss: 2.0172\n",
      "Epoch 12/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2889 - loss: 2.0093 - val_acc: 0.2797 - val_loss: 2.0113\n",
      "Epoch 13/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.2902 - loss: 2.0021 - val_acc: 0.2797 - val_loss: 2.0058\n",
      "Epoch 14/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3004 - loss: 1.9954 - val_acc: 0.2877 - val_loss: 2.0006\n",
      "Epoch 15/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3031 - loss: 1.9891 - val_acc: 0.2857 - val_loss: 1.9957\n",
      "Epoch 16/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3041 - loss: 1.9830 - val_acc: 0.2897 - val_loss: 1.9909\n",
      "Epoch 17/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3093 - loss: 1.9771 - val_acc: 0.2897 - val_loss: 1.9863\n",
      "Epoch 18/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3113 - loss: 1.9714 - val_acc: 0.2938 - val_loss: 1.9818\n",
      "Epoch 19/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3121 - loss: 1.9658 - val_acc: 0.2978 - val_loss: 1.9775\n",
      "Epoch 20/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3131 - loss: 1.9602 - val_acc: 0.2978 - val_loss: 1.9731\n",
      "Epoch 21/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3160 - loss: 1.9548 - val_acc: 0.3018 - val_loss: 1.9687\n",
      "Epoch 22/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3188 - loss: 1.9493 - val_acc: 0.3038 - val_loss: 1.9643\n",
      "Epoch 23/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3236 - loss: 1.9439 - val_acc: 0.3038 - val_loss: 1.9599\n",
      "Epoch 24/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3256 - loss: 1.9385 - val_acc: 0.3018 - val_loss: 1.9555\n",
      "Epoch 25/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3263 - loss: 1.9331 - val_acc: 0.3018 - val_loss: 1.9511\n",
      "Epoch 26/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3286 - loss: 1.9276 - val_acc: 0.2998 - val_loss: 1.9466\n",
      "Epoch 27/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3286 - loss: 1.9221 - val_acc: 0.2998 - val_loss: 1.9420\n",
      "Epoch 28/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3321 - loss: 1.9166 - val_acc: 0.3018 - val_loss: 1.9374\n",
      "Epoch 29/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3349 - loss: 1.9110 - val_acc: 0.3018 - val_loss: 1.9327\n",
      "Epoch 30/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3353 - loss: 1.9055 - val_acc: 0.3038 - val_loss: 1.9279\n",
      "Epoch 31/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3347 - loss: 1.8998 - val_acc: 0.3078 - val_loss: 1.9229\n",
      "Epoch 32/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3359 - loss: 1.8934 - val_acc: 0.3078 - val_loss: 1.9179\n",
      "Epoch 33/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3366 - loss: 1.8885 - val_acc: 0.3078 - val_loss: 1.9127\n",
      "Epoch 34/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3381 - loss: 1.8827 - val_acc: 0.3078 - val_loss: 1.9075\n",
      "Epoch 35/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3404 - loss: 1.8768 - val_acc: 0.3159 - val_loss: 1.9023\n",
      "Epoch 36/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3418 - loss: 1.8710 - val_acc: 0.3159 - val_loss: 1.8969\n",
      "Epoch 37/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3428 - loss: 1.8650 - val_acc: 0.3159 - val_loss: 1.8914\n",
      "Epoch 38/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3472 - loss: 1.8589 - val_acc: 0.3159 - val_loss: 1.8859\n",
      "Epoch 39/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3496 - loss: 1.8526 - val_acc: 0.3179 - val_loss: 1.8801\n",
      "Epoch 40/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3521 - loss: 1.8465 - val_acc: 0.3219 - val_loss: 1.8743\n",
      "Epoch 41/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3533 - loss: 1.8402 - val_acc: 0.3219 - val_loss: 1.8684\n",
      "Epoch 42/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3543 - loss: 1.8338 - val_acc: 0.3260 - val_loss: 1.8623\n",
      "Epoch 43/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3562 - loss: 1.8272 - val_acc: 0.3260 - val_loss: 1.8561\n",
      "Epoch 44/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3581 - loss: 1.8207 - val_acc: 0.3260 - val_loss: 1.8498\n",
      "Epoch 45/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3582 - loss: 1.8139 - val_acc: 0.3320 - val_loss: 1.8434\n",
      "Epoch 46/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3596 - loss: 1.8070 - val_acc: 0.3320 - val_loss: 1.8369\n",
      "Epoch 47/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3609 - loss: 1.8002 - val_acc: 0.3320 - val_loss: 1.8303\n",
      "Epoch 48/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3623 - loss: 1.7932 - val_acc: 0.3320 - val_loss: 1.8237\n",
      "Epoch 49/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3637 - loss: 1.7862 - val_acc: 0.3320 - val_loss: 1.8169\n",
      "Epoch 50/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3641 - loss: 1.7789 - val_acc: 0.3340 - val_loss: 1.8100\n",
      "Epoch 51/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3656 - loss: 1.7717 - val_acc: 0.3380 - val_loss: 1.8030\n",
      "Epoch 52/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3686 - loss: 1.7644 - val_acc: 0.3400 - val_loss: 1.7959\n",
      "Epoch 53/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3716 - loss: 1.7571 - val_acc: 0.3360 - val_loss: 1.7887\n",
      "Epoch 54/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3731 - loss: 1.7496 - val_acc: 0.3340 - val_loss: 1.7815\n",
      "Epoch 55/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3739 - loss: 1.7424 - val_acc: 0.3360 - val_loss: 1.7743\n",
      "Epoch 56/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3748 - loss: 1.7347 - val_acc: 0.3360 - val_loss: 1.7670\n",
      "Epoch 57/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3767 - loss: 1.7273 - val_acc: 0.3340 - val_loss: 1.7596\n",
      "Epoch 58/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3823 - loss: 1.7195 - val_acc: 0.3360 - val_loss: 1.7522\n",
      "Epoch 59/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3857 - loss: 1.7120 - val_acc: 0.3360 - val_loss: 1.7447\n",
      "Epoch 60/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3871 - loss: 1.7042 - val_acc: 0.3360 - val_loss: 1.7373\n",
      "Epoch 61/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3879 - loss: 1.6966 - val_acc: 0.3360 - val_loss: 1.7297\n",
      "Epoch 62/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3884 - loss: 1.6891 - val_acc: 0.3380 - val_loss: 1.7222\n",
      "Epoch 63/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3898 - loss: 1.6811 - val_acc: 0.3400 - val_loss: 1.7147\n",
      "Epoch 64/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.3925 - loss: 1.6734 - val_acc: 0.3421 - val_loss: 1.7072\n",
      "Epoch 65/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3927 - loss: 1.6657 - val_acc: 0.3481 - val_loss: 1.6997\n",
      "Epoch 66/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3929 - loss: 1.6580 - val_acc: 0.3541 - val_loss: 1.6922\n",
      "Epoch 67/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3929 - loss: 1.6504 - val_acc: 0.3541 - val_loss: 1.6847\n",
      "Epoch 68/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3939 - loss: 1.6429 - val_acc: 0.3541 - val_loss: 1.6772\n",
      "Epoch 69/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3966 - loss: 1.6351 - val_acc: 0.3602 - val_loss: 1.6698\n",
      "Epoch 70/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3973 - loss: 1.6275 - val_acc: 0.3622 - val_loss: 1.6623\n",
      "Epoch 71/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.3972 - loss: 1.6200 - val_acc: 0.3642 - val_loss: 1.6549\n",
      "Epoch 72/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4014 - loss: 1.6125 - val_acc: 0.3702 - val_loss: 1.6475\n",
      "Epoch 73/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4044 - loss: 1.6051 - val_acc: 0.3702 - val_loss: 1.6402\n",
      "Epoch 74/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4084 - loss: 1.5977 - val_acc: 0.3742 - val_loss: 1.6329\n",
      "Epoch 75/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4106 - loss: 1.5904 - val_acc: 0.3763 - val_loss: 1.6257\n",
      "Epoch 76/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4112 - loss: 1.5832 - val_acc: 0.3763 - val_loss: 1.6185\n",
      "Epoch 77/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4112 - loss: 1.5760 - val_acc: 0.3783 - val_loss: 1.6113\n",
      "Epoch 78/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4123 - loss: 1.5692 - val_acc: 0.3783 - val_loss: 1.6042\n",
      "Epoch 79/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4128 - loss: 1.5617 - val_acc: 0.3783 - val_loss: 1.5972\n",
      "Epoch 80/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4142 - loss: 1.5546 - val_acc: 0.3823 - val_loss: 1.5903\n",
      "Epoch 81/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4144 - loss: 1.5476 - val_acc: 0.3843 - val_loss: 1.5833\n",
      "Epoch 82/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4162 - loss: 1.5406 - val_acc: 0.3863 - val_loss: 1.5764\n",
      "Epoch 83/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4163 - loss: 1.5336 - val_acc: 0.3903 - val_loss: 1.5696\n",
      "Epoch 84/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4167 - loss: 1.5262 - val_acc: 0.3944 - val_loss: 1.5628\n",
      "Epoch 85/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4183 - loss: 1.5197 - val_acc: 0.3944 - val_loss: 1.5561\n",
      "Epoch 86/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4175 - loss: 1.5130 - val_acc: 0.3984 - val_loss: 1.5494\n",
      "Epoch 87/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4215 - loss: 1.5062 - val_acc: 0.4044 - val_loss: 1.5428\n",
      "Epoch 88/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4228 - loss: 1.4996 - val_acc: 0.4044 - val_loss: 1.5362\n",
      "Epoch 89/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4256 - loss: 1.4931 - val_acc: 0.4064 - val_loss: 1.5297\n",
      "Epoch 90/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4267 - loss: 1.4867 - val_acc: 0.4085 - val_loss: 1.5233\n",
      "Epoch 91/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4280 - loss: 1.4801 - val_acc: 0.4125 - val_loss: 1.5170\n",
      "Epoch 92/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4289 - loss: 1.4735 - val_acc: 0.4125 - val_loss: 1.5107\n",
      "Epoch 93/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4316 - loss: 1.4671 - val_acc: 0.4165 - val_loss: 1.5044\n",
      "Epoch 94/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4353 - loss: 1.4610 - val_acc: 0.4185 - val_loss: 1.4982\n",
      "Epoch 95/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4361 - loss: 1.4546 - val_acc: 0.4185 - val_loss: 1.4921\n",
      "Epoch 96/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4393 - loss: 1.4484 - val_acc: 0.4205 - val_loss: 1.4860\n",
      "Epoch 97/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4398 - loss: 1.4423 - val_acc: 0.4225 - val_loss: 1.4800\n",
      "Epoch 98/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4417 - loss: 1.4363 - val_acc: 0.4266 - val_loss: 1.4740\n",
      "Epoch 99/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4443 - loss: 1.4303 - val_acc: 0.4286 - val_loss: 1.4681\n",
      "Epoch 100/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4481 - loss: 1.4246 - val_acc: 0.4286 - val_loss: 1.4623\n",
      "Epoch 101/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4483 - loss: 1.4197 - val_acc: 0.4306 - val_loss: 1.4566\n",
      "Epoch 102/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4538 - loss: 1.4128 - val_acc: 0.4326 - val_loss: 1.4508\n",
      "Epoch 103/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4566 - loss: 1.4070 - val_acc: 0.4386 - val_loss: 1.4451\n",
      "Epoch 104/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4660 - loss: 1.4013 - val_acc: 0.4406 - val_loss: 1.4395\n",
      "Epoch 105/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4662 - loss: 1.3957 - val_acc: 0.4447 - val_loss: 1.4339\n",
      "Epoch 106/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4721 - loss: 1.3895 - val_acc: 0.4507 - val_loss: 1.4283\n",
      "Epoch 107/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4737 - loss: 1.3846 - val_acc: 0.4628 - val_loss: 1.4228\n",
      "Epoch 108/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4755 - loss: 1.3791 - val_acc: 0.4648 - val_loss: 1.4173\n",
      "Epoch 109/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4782 - loss: 1.3738 - val_acc: 0.4648 - val_loss: 1.4119\n",
      "Epoch 110/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4793 - loss: 1.3684 - val_acc: 0.4688 - val_loss: 1.4066\n",
      "Epoch 111/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4794 - loss: 1.3629 - val_acc: 0.4708 - val_loss: 1.4013\n",
      "Epoch 112/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4828 - loss: 1.3571 - val_acc: 0.4728 - val_loss: 1.3961\n",
      "Epoch 113/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4844 - loss: 1.3525 - val_acc: 0.4748 - val_loss: 1.3909\n",
      "Epoch 114/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4859 - loss: 1.3473 - val_acc: 0.4769 - val_loss: 1.3858\n",
      "Epoch 115/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4877 - loss: 1.3422 - val_acc: 0.4809 - val_loss: 1.3806\n",
      "Epoch 116/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4948 - loss: 1.3366 - val_acc: 0.4829 - val_loss: 1.3756\n",
      "Epoch 117/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4969 - loss: 1.3321 - val_acc: 0.4869 - val_loss: 1.3706\n",
      "Epoch 118/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4998 - loss: 1.3268 - val_acc: 0.4889 - val_loss: 1.3656\n",
      "Epoch 119/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5012 - loss: 1.3222 - val_acc: 0.4889 - val_loss: 1.3607\n",
      "Epoch 120/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5032 - loss: 1.3173 - val_acc: 0.4909 - val_loss: 1.3558\n",
      "Epoch 121/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5047 - loss: 1.3124 - val_acc: 0.4930 - val_loss: 1.3510\n",
      "Epoch 122/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5053 - loss: 1.3075 - val_acc: 0.4990 - val_loss: 1.3462\n",
      "Epoch 123/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5060 - loss: 1.3027 - val_acc: 0.4990 - val_loss: 1.3414\n",
      "Epoch 124/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5073 - loss: 1.2979 - val_acc: 0.5030 - val_loss: 1.3366\n",
      "Epoch 125/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5105 - loss: 1.2932 - val_acc: 0.5030 - val_loss: 1.3319\n",
      "Epoch 126/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5125 - loss: 1.2885 - val_acc: 0.5050 - val_loss: 1.3271\n",
      "Epoch 127/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5145 - loss: 1.2838 - val_acc: 0.5070 - val_loss: 1.3225\n",
      "Epoch 128/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5164 - loss: 1.2791 - val_acc: 0.5070 - val_loss: 1.3178\n",
      "Epoch 129/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5168 - loss: 1.2745 - val_acc: 0.5070 - val_loss: 1.3132\n",
      "Epoch 130/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5185 - loss: 1.2701 - val_acc: 0.5070 - val_loss: 1.3086\n",
      "Epoch 131/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5198 - loss: 1.2653 - val_acc: 0.5091 - val_loss: 1.3040\n",
      "Epoch 132/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5205 - loss: 1.2608 - val_acc: 0.5111 - val_loss: 1.2995\n",
      "Epoch 133/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5205 - loss: 1.2563 - val_acc: 0.5111 - val_loss: 1.2949\n",
      "Epoch 134/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5213 - loss: 1.2520 - val_acc: 0.5131 - val_loss: 1.2904\n",
      "Epoch 135/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5240 - loss: 1.2474 - val_acc: 0.5151 - val_loss: 1.2860\n",
      "Epoch 136/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5251 - loss: 1.2430 - val_acc: 0.5171 - val_loss: 1.2815\n",
      "Epoch 137/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5259 - loss: 1.2386 - val_acc: 0.5171 - val_loss: 1.2771\n",
      "Epoch 138/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5286 - loss: 1.2340 - val_acc: 0.5191 - val_loss: 1.2727\n",
      "Epoch 139/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5297 - loss: 1.2299 - val_acc: 0.5191 - val_loss: 1.2684\n",
      "Epoch 140/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5313 - loss: 1.2256 - val_acc: 0.5191 - val_loss: 1.2641\n",
      "Epoch 141/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5319 - loss: 1.2218 - val_acc: 0.5252 - val_loss: 1.2597\n",
      "Epoch 142/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5335 - loss: 1.2172 - val_acc: 0.5292 - val_loss: 1.2555\n",
      "Epoch 143/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5338 - loss: 1.2130 - val_acc: 0.5292 - val_loss: 1.2512\n",
      "Epoch 144/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5362 - loss: 1.2091 - val_acc: 0.5332 - val_loss: 1.2470\n",
      "Epoch 145/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5379 - loss: 1.2047 - val_acc: 0.5352 - val_loss: 1.2429\n",
      "Epoch 146/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5385 - loss: 1.2006 - val_acc: 0.5352 - val_loss: 1.2387\n",
      "Epoch 147/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5391 - loss: 1.1965 - val_acc: 0.5372 - val_loss: 1.2347\n",
      "Epoch 148/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5393 - loss: 1.1924 - val_acc: 0.5372 - val_loss: 1.2306\n",
      "Epoch 149/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5417 - loss: 1.1884 - val_acc: 0.5372 - val_loss: 1.2265\n",
      "Epoch 150/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5422 - loss: 1.1844 - val_acc: 0.5392 - val_loss: 1.2225\n",
      "Epoch 151/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5447 - loss: 1.1805 - val_acc: 0.5412 - val_loss: 1.2185\n",
      "Epoch 152/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5458 - loss: 1.1765 - val_acc: 0.5433 - val_loss: 1.2146\n",
      "Epoch 153/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5475 - loss: 1.1726 - val_acc: 0.5433 - val_loss: 1.2106\n",
      "Epoch 154/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5492 - loss: 1.1687 - val_acc: 0.5433 - val_loss: 1.2067\n",
      "Epoch 155/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5499 - loss: 1.1649 - val_acc: 0.5453 - val_loss: 1.2029\n",
      "Epoch 156/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5520 - loss: 1.1609 - val_acc: 0.5433 - val_loss: 1.1990\n",
      "Epoch 157/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5538 - loss: 1.1573 - val_acc: 0.5473 - val_loss: 1.1952\n",
      "Epoch 158/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5540 - loss: 1.1535 - val_acc: 0.5493 - val_loss: 1.1914\n",
      "Epoch 159/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5552 - loss: 1.1498 - val_acc: 0.5493 - val_loss: 1.1876\n",
      "Epoch 160/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5553 - loss: 1.1461 - val_acc: 0.5493 - val_loss: 1.1839\n",
      "Epoch 161/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5561 - loss: 1.1424 - val_acc: 0.5513 - val_loss: 1.1802\n",
      "Epoch 162/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5567 - loss: 1.1388 - val_acc: 0.5513 - val_loss: 1.1765\n",
      "Epoch 163/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5569 - loss: 1.1351 - val_acc: 0.5533 - val_loss: 1.1728\n",
      "Epoch 164/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5598 - loss: 1.1315 - val_acc: 0.5553 - val_loss: 1.1692\n",
      "Epoch 165/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5603 - loss: 1.1280 - val_acc: 0.5553 - val_loss: 1.1656\n",
      "Epoch 166/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5603 - loss: 1.1244 - val_acc: 0.5573 - val_loss: 1.1620\n",
      "Epoch 167/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5608 - loss: 1.1209 - val_acc: 0.5573 - val_loss: 1.1585\n",
      "Epoch 168/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5634 - loss: 1.1174 - val_acc: 0.5573 - val_loss: 1.1549\n",
      "Epoch 169/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5635 - loss: 1.1139 - val_acc: 0.5573 - val_loss: 1.1514\n",
      "Epoch 170/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5635 - loss: 1.1104 - val_acc: 0.5573 - val_loss: 1.1479\n",
      "Epoch 171/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5640 - loss: 1.1073 - val_acc: 0.5573 - val_loss: 1.1444\n",
      "Epoch 172/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5651 - loss: 1.1036 - val_acc: 0.5594 - val_loss: 1.1410\n",
      "Epoch 173/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5653 - loss: 1.1002 - val_acc: 0.5594 - val_loss: 1.1375\n",
      "Epoch 174/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5654 - loss: 1.0968 - val_acc: 0.5614 - val_loss: 1.1341\n",
      "Epoch 175/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5657 - loss: 1.0935 - val_acc: 0.5614 - val_loss: 1.1307\n",
      "Epoch 176/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5662 - loss: 1.0902 - val_acc: 0.5614 - val_loss: 1.1274\n",
      "Epoch 177/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5678 - loss: 1.0869 - val_acc: 0.5634 - val_loss: 1.1241\n",
      "Epoch 178/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5685 - loss: 1.0836 - val_acc: 0.5654 - val_loss: 1.1208\n",
      "Epoch 179/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5685 - loss: 1.0804 - val_acc: 0.5694 - val_loss: 1.1175\n",
      "Epoch 180/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5691 - loss: 1.0771 - val_acc: 0.5734 - val_loss: 1.1142\n",
      "Epoch 181/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5695 - loss: 1.0739 - val_acc: 0.5734 - val_loss: 1.1110\n",
      "Epoch 182/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5705 - loss: 1.0708 - val_acc: 0.5755 - val_loss: 1.1077\n",
      "Epoch 183/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5741 - loss: 1.0676 - val_acc: 0.5775 - val_loss: 1.1045\n",
      "Epoch 184/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5747 - loss: 1.0644 - val_acc: 0.5795 - val_loss: 1.1013\n",
      "Epoch 185/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5757 - loss: 1.0613 - val_acc: 0.5815 - val_loss: 1.0982\n",
      "Epoch 186/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5790 - loss: 1.0587 - val_acc: 0.5835 - val_loss: 1.0950\n",
      "Epoch 187/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5806 - loss: 1.0551 - val_acc: 0.5855 - val_loss: 1.0919\n",
      "Epoch 188/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5809 - loss: 1.0522 - val_acc: 0.5895 - val_loss: 1.0888\n",
      "Epoch 189/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5838 - loss: 1.0490 - val_acc: 0.5895 - val_loss: 1.0857\n",
      "Epoch 190/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5829 - loss: 1.0461 - val_acc: 0.5895 - val_loss: 1.0826\n",
      "Epoch 191/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5851 - loss: 1.0430 - val_acc: 0.5895 - val_loss: 1.0795\n",
      "Epoch 192/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5866 - loss: 1.0400 - val_acc: 0.5895 - val_loss: 1.0765\n",
      "Epoch 193/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5888 - loss: 1.0370 - val_acc: 0.5895 - val_loss: 1.0735\n",
      "Epoch 194/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5878 - loss: 1.0342 - val_acc: 0.5915 - val_loss: 1.0705\n",
      "Epoch 195/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5884 - loss: 1.0312 - val_acc: 0.5936 - val_loss: 1.0675\n",
      "Epoch 196/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5902 - loss: 1.0282 - val_acc: 0.5936 - val_loss: 1.0646\n",
      "Epoch 197/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5909 - loss: 1.0253 - val_acc: 0.5936 - val_loss: 1.0616\n",
      "Epoch 198/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5907 - loss: 1.0226 - val_acc: 0.5936 - val_loss: 1.0587\n",
      "Epoch 199/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5936 - loss: 1.0196 - val_acc: 0.5936 - val_loss: 1.0558\n",
      "Epoch 200/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5936 - loss: 1.0167 - val_acc: 0.5996 - val_loss: 1.0529\n",
      "Epoch 201/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5939 - loss: 1.0139 - val_acc: 0.6016 - val_loss: 1.0501\n",
      "Epoch 202/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5945 - loss: 1.0111 - val_acc: 0.6016 - val_loss: 1.0472\n",
      "Epoch 203/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5996 - loss: 1.0083 - val_acc: 0.6036 - val_loss: 1.0444\n",
      "Epoch 204/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6015 - loss: 1.0055 - val_acc: 0.6056 - val_loss: 1.0415\n",
      "Epoch 205/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6014 - loss: 1.0028 - val_acc: 0.6097 - val_loss: 1.0387\n",
      "Epoch 206/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6022 - loss: 1.0000 - val_acc: 0.6117 - val_loss: 1.0359\n",
      "Epoch 207/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6073 - loss: 0.9973 - val_acc: 0.6137 - val_loss: 1.0332\n",
      "Epoch 208/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6090 - loss: 0.9946 - val_acc: 0.6157 - val_loss: 1.0304\n",
      "Epoch 209/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6110 - loss: 0.9919 - val_acc: 0.6177 - val_loss: 1.0277\n",
      "Epoch 210/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6113 - loss: 0.9892 - val_acc: 0.6177 - val_loss: 1.0250\n",
      "Epoch 211/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6114 - loss: 0.9865 - val_acc: 0.6177 - val_loss: 1.0222\n",
      "Epoch 212/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6127 - loss: 0.9839 - val_acc: 0.6197 - val_loss: 1.0195\n",
      "Epoch 213/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6135 - loss: 0.9812 - val_acc: 0.6197 - val_loss: 1.0169\n",
      "Epoch 214/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6159 - loss: 0.9788 - val_acc: 0.6197 - val_loss: 1.0142\n",
      "Epoch 215/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6168 - loss: 0.9760 - val_acc: 0.6197 - val_loss: 1.0116\n",
      "Epoch 216/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6178 - loss: 0.9734 - val_acc: 0.6217 - val_loss: 1.0089\n",
      "Epoch 217/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6237 - loss: 0.9708 - val_acc: 0.6217 - val_loss: 1.0063\n",
      "Epoch 218/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6237 - loss: 0.9682 - val_acc: 0.6237 - val_loss: 1.0037\n",
      "Epoch 219/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6239 - loss: 0.9657 - val_acc: 0.6258 - val_loss: 1.0012\n",
      "Epoch 220/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6282 - loss: 0.9631 - val_acc: 0.6298 - val_loss: 0.9986\n",
      "Epoch 221/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6305 - loss: 0.9606 - val_acc: 0.6318 - val_loss: 0.9960\n",
      "Epoch 222/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6317 - loss: 0.9581 - val_acc: 0.6318 - val_loss: 0.9935\n",
      "Epoch 223/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6329 - loss: 0.9556 - val_acc: 0.6318 - val_loss: 0.9909\n",
      "Epoch 224/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6365 - loss: 0.9531 - val_acc: 0.6358 - val_loss: 0.9884\n",
      "Epoch 225/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6386 - loss: 0.9506 - val_acc: 0.6378 - val_loss: 0.9859\n",
      "Epoch 226/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6396 - loss: 0.9483 - val_acc: 0.6419 - val_loss: 0.9834\n",
      "Epoch 227/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6419 - loss: 0.9457 - val_acc: 0.6459 - val_loss: 0.9810\n",
      "Epoch 228/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6439 - loss: 0.9434 - val_acc: 0.6479 - val_loss: 0.9785\n",
      "Epoch 229/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6478 - loss: 0.9409 - val_acc: 0.6539 - val_loss: 0.9760\n",
      "Epoch 230/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6510 - loss: 0.9384 - val_acc: 0.6539 - val_loss: 0.9736\n",
      "Epoch 231/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6529 - loss: 0.9360 - val_acc: 0.6600 - val_loss: 0.9712\n",
      "Epoch 232/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6569 - loss: 0.9336 - val_acc: 0.6660 - val_loss: 0.9687\n",
      "Epoch 233/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6580 - loss: 0.9314 - val_acc: 0.6680 - val_loss: 0.9664\n",
      "Epoch 234/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6604 - loss: 0.9289 - val_acc: 0.6740 - val_loss: 0.9640\n",
      "Epoch 235/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6646 - loss: 0.9266 - val_acc: 0.6781 - val_loss: 0.9616\n",
      "Epoch 236/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6680 - loss: 0.9242 - val_acc: 0.6781 - val_loss: 0.9592\n",
      "Epoch 237/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6738 - loss: 0.9219 - val_acc: 0.6781 - val_loss: 0.9569\n",
      "Epoch 238/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6771 - loss: 0.9196 - val_acc: 0.6781 - val_loss: 0.9545\n",
      "Epoch 239/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6806 - loss: 0.9173 - val_acc: 0.6801 - val_loss: 0.9522\n",
      "Epoch 240/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6825 - loss: 0.9150 - val_acc: 0.6861 - val_loss: 0.9499\n",
      "Epoch 241/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6853 - loss: 0.9127 - val_acc: 0.6881 - val_loss: 0.9476\n",
      "Epoch 242/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6878 - loss: 0.9105 - val_acc: 0.6901 - val_loss: 0.9453\n",
      "Epoch 243/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6944 - loss: 0.9082 - val_acc: 0.6901 - val_loss: 0.9430\n",
      "Epoch 244/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6930 - loss: 0.9060 - val_acc: 0.6922 - val_loss: 0.9408\n",
      "Epoch 245/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6992 - loss: 0.9038 - val_acc: 0.6962 - val_loss: 0.9385\n",
      "Epoch 246/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7010 - loss: 0.9015 - val_acc: 0.6982 - val_loss: 0.9363\n",
      "Epoch 247/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7040 - loss: 0.8993 - val_acc: 0.7022 - val_loss: 0.9341\n",
      "Epoch 248/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7067 - loss: 0.8971 - val_acc: 0.7042 - val_loss: 0.9319\n",
      "Epoch 249/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7083 - loss: 0.8950 - val_acc: 0.7062 - val_loss: 0.9297\n",
      "Epoch 250/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7090 - loss: 0.8928 - val_acc: 0.7082 - val_loss: 0.9275\n",
      "Epoch 251/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7110 - loss: 0.8906 - val_acc: 0.7123 - val_loss: 0.9253\n",
      "Epoch 252/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7151 - loss: 0.8886 - val_acc: 0.7143 - val_loss: 0.9231\n",
      "Epoch 253/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7185 - loss: 0.8864 - val_acc: 0.7163 - val_loss: 0.9210\n",
      "Epoch 254/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7200 - loss: 0.8842 - val_acc: 0.7183 - val_loss: 0.9188\n",
      "Epoch 255/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7210 - loss: 0.8821 - val_acc: 0.7203 - val_loss: 0.9167\n",
      "Epoch 256/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7230 - loss: 0.8800 - val_acc: 0.7243 - val_loss: 0.9145\n",
      "Epoch 257/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7241 - loss: 0.8779 - val_acc: 0.7264 - val_loss: 0.9124\n",
      "Epoch 258/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7298 - loss: 0.8759 - val_acc: 0.7304 - val_loss: 0.9103\n",
      "Epoch 259/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7317 - loss: 0.8739 - val_acc: 0.7304 - val_loss: 0.9082\n",
      "Epoch 260/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7330 - loss: 0.8717 - val_acc: 0.7324 - val_loss: 0.9061\n",
      "Epoch 261/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7324 - loss: 0.8696 - val_acc: 0.7324 - val_loss: 0.9040\n",
      "Epoch 262/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7376 - loss: 0.8676 - val_acc: 0.7324 - val_loss: 0.9020\n",
      "Epoch 263/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7399 - loss: 0.8656 - val_acc: 0.7324 - val_loss: 0.8999\n",
      "Epoch 264/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7438 - loss: 0.8636 - val_acc: 0.7324 - val_loss: 0.8978\n",
      "Epoch 265/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7445 - loss: 0.8615 - val_acc: 0.7344 - val_loss: 0.8958\n",
      "Epoch 266/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7446 - loss: 0.8595 - val_acc: 0.7364 - val_loss: 0.8938\n",
      "Epoch 267/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7447 - loss: 0.8575 - val_acc: 0.7384 - val_loss: 0.8917\n",
      "Epoch 268/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7447 - loss: 0.8556 - val_acc: 0.7384 - val_loss: 0.8897\n",
      "Epoch 269/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7455 - loss: 0.8536 - val_acc: 0.7425 - val_loss: 0.8877\n",
      "Epoch 270/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7471 - loss: 0.8519 - val_acc: 0.7445 - val_loss: 0.8857\n",
      "Epoch 271/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7473 - loss: 0.8496 - val_acc: 0.7445 - val_loss: 0.8837\n",
      "Epoch 272/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7482 - loss: 0.8477 - val_acc: 0.7445 - val_loss: 0.8818\n",
      "Epoch 273/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7483 - loss: 0.8457 - val_acc: 0.7485 - val_loss: 0.8798\n",
      "Epoch 274/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7498 - loss: 0.8438 - val_acc: 0.7485 - val_loss: 0.8779\n",
      "Epoch 275/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7510 - loss: 0.8419 - val_acc: 0.7485 - val_loss: 0.8759\n",
      "Epoch 276/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7525 - loss: 0.8395 - val_acc: 0.7485 - val_loss: 0.8740\n",
      "Epoch 277/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7535 - loss: 0.8380 - val_acc: 0.7485 - val_loss: 0.8720\n",
      "Epoch 278/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7559 - loss: 0.8361 - val_acc: 0.7505 - val_loss: 0.8701\n",
      "Epoch 279/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7569 - loss: 0.8346 - val_acc: 0.7505 - val_loss: 0.8682\n",
      "Epoch 280/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7595 - loss: 0.8324 - val_acc: 0.7505 - val_loss: 0.8663\n",
      "Epoch 281/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7599 - loss: 0.8305 - val_acc: 0.7545 - val_loss: 0.8644\n",
      "Epoch 282/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7614 - loss: 0.8286 - val_acc: 0.7545 - val_loss: 0.8625\n",
      "Epoch 283/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7620 - loss: 0.8268 - val_acc: 0.7565 - val_loss: 0.8606\n",
      "Epoch 284/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7620 - loss: 0.8249 - val_acc: 0.7606 - val_loss: 0.8587\n",
      "Epoch 285/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7620 - loss: 0.8231 - val_acc: 0.7606 - val_loss: 0.8569\n",
      "Epoch 286/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7629 - loss: 0.8212 - val_acc: 0.7606 - val_loss: 0.8550\n",
      "Epoch 287/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7634 - loss: 0.8189 - val_acc: 0.7626 - val_loss: 0.8532\n",
      "Epoch 288/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7648 - loss: 0.8176 - val_acc: 0.7626 - val_loss: 0.8513\n",
      "Epoch 289/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7669 - loss: 0.8158 - val_acc: 0.7626 - val_loss: 0.8495\n",
      "Epoch 290/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7692 - loss: 0.8140 - val_acc: 0.7626 - val_loss: 0.8477\n",
      "Epoch 291/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7705 - loss: 0.8122 - val_acc: 0.7626 - val_loss: 0.8459\n",
      "Epoch 292/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7717 - loss: 0.8104 - val_acc: 0.7626 - val_loss: 0.8441\n",
      "Epoch 293/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7724 - loss: 0.8086 - val_acc: 0.7626 - val_loss: 0.8422\n",
      "Epoch 294/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7721 - loss: 0.8068 - val_acc: 0.7626 - val_loss: 0.8404\n",
      "Epoch 295/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7727 - loss: 0.8051 - val_acc: 0.7626 - val_loss: 0.8387\n",
      "Epoch 296/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7744 - loss: 0.8033 - val_acc: 0.7646 - val_loss: 0.8369\n",
      "Epoch 297/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7744 - loss: 0.8016 - val_acc: 0.7646 - val_loss: 0.8351\n",
      "Epoch 298/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7744 - loss: 0.7998 - val_acc: 0.7666 - val_loss: 0.8334\n",
      "Epoch 299/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7758 - loss: 0.7981 - val_acc: 0.7666 - val_loss: 0.8316\n",
      "Epoch 300/300\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7750 - loss: 0.7959 - val_acc: 0.7666 - val_loss: 0.8298\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "\n",
    "# Realmente hace una estandardization. Necestiamos hacer un \"fit\" previo como con el StandardScaler\n",
    "norm_layer = tf.keras.layers.Normalization() \n",
    " \n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics =[\"acc\"])\n",
    "\n",
    "# esto es similar al fit. Depende la versión de tensorflow puede o no trabajar directamente con DataFrames\n",
    "norm_layer.adapt(X_num.to_numpy())\n",
    "\n",
    "history = model.fit(X_num, y_num, validation_split=0.2, epochs=300, callbacks=earlyS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIbIsJSXkHaO",
    "outputId": "848ced04-52f5-4f5c-9fb5-9cdfd8dcf469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7283 - loss: 0.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8436590433120728, 0.7266880869865417]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set[numericas], test_set[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDilaUJXkHaO",
    "outputId": "b354e33f-054b-4a07-9bff-a86c917a5261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model.predict(test_set[numericas])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aorAbuYlkHaP",
    "outputId": "b0a644d1-1804-4b5d-e89a-277d11be2786",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        62\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.73      0.83      0.78        23\n",
      "           3       0.50      0.28      0.36        18\n",
      "           4       0.59      0.63      0.61        27\n",
      "           5       0.00      0.00      0.00        38\n",
      "           6       0.21      0.13      0.16        83\n",
      "           7       0.53      0.99      0.69        94\n",
      "           8       0.99      0.85      0.92       110\n",
      "           9       0.96      1.00      0.98       151\n",
      "\n",
      "    accuracy                           0.73       622\n",
      "   macro avg       0.53      0.57      0.54       622\n",
      "weighted avg       0.66      0.73      0.68       622\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set[target], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kefzb22QkHaP"
   },
   "source": [
    "Bien, pues ya tenemos baseline y una forma sencilla de incorporar la normalización a nuestro modelo, vamos con el resto de transformaciones, pero ya en la siguiente sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7_3TDcDkHaP"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWd1DYFPkHaP"
   },
   "source": [
    "### Transformación de variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqBwArE2kHaP"
   },
   "source": [
    "Vamos a transformar las categóricas y lo vamos a hacer con un \"ordinal encoder\" por un lado y con un \"onehot\" por otro, eso sí, usando las capas de Keras, y cuáles son categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Qzx9tH6kHaQ",
    "outputId": "3484ac08-9bcb-4bff-c47d-5de495bf8264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2485 entries, 2686 to 860\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   urlDrugName           2485 non-null   object \n",
      " 1   rating                2485 non-null   int64  \n",
      " 2   effectiveness         2485 non-null   object \n",
      " 3   sideEffects           2485 non-null   object \n",
      " 4   condition             2485 non-null   object \n",
      " 5   benefitsReview        2485 non-null   object \n",
      " 6   sideEffectsReview     2485 non-null   object \n",
      " 7   commentsReview        2485 non-null   object \n",
      " 8   Sales                 2485 non-null   int64  \n",
      " 9   Production            2485 non-null   float64\n",
      " 10  benefitsReview_wc     2485 non-null   int64  \n",
      " 11  sideEffectsReview_wc  2485 non-null   int64  \n",
      " 12  commentsReview_wc     2485 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(7)\n",
      "memory usage: 271.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsOkRvlukHaQ"
   },
   "source": [
    "Tiene pinta de que todas las que son objetc que no son Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6M6uvQvAkHaQ",
    "outputId": "160d4447-bde2-4880-a039-438a4ee542c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlDrugName', 'effectiveness', 'sideEffects', 'condition']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definir las categóricas\n",
    "categoricals = [col for col in train_set.columns if \"Review\" not in col and train_set[col].dtype == \"object\"]\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtQ_so3wkHaQ"
   },
   "source": [
    "Hagamos un check de cardinalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6-o_l2NkHaQ",
    "outputId": "d276f953-ea42-4688-8dfc-55a44dceadce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para <urlDrugName>: 463\n",
      "Para <effectiveness>: 5\n",
      "Para <sideEffects>: 5\n",
      "Para <condition>: 1203\n"
     ]
    }
   ],
   "source": [
    "for col in categoricals:\n",
    "    print(f\"Para <{col}>: {train_set[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "rCWHNH3okHaQ",
    "outputId": "b35ff614-da65-43b4-9f3d-3bdc4dc3d4ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "depression                        182\n",
       "acne                              135\n",
       "anxiety                            51\n",
       "insomnia                           41\n",
       "birth control                      34\n",
       "                                 ... \n",
       "major sinus infection               1\n",
       "bipolar/raciness/insomnia           1\n",
       "anxiety/insomnia/                   1\n",
       "infected site of oreal surgery      1\n",
       "all over and various type pain      1\n",
       "Name: count, Length: 1203, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI_n9ipQkHaQ"
   },
   "source": [
    "Tenemos que quitar la url y condition. Esta además tendría que tener un tratamiento particular (entre vectorización y compresión de categorías, que no vamos a hacer por tiempo y espacio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMzxqdtAkHaR",
    "outputId": "a431f41d-f128-44a8-ac53-079e3b5be1d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effectiveness', 'sideEffects']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals.remove(\"urlDrugName\")\n",
    "categoricals.remove(\"condition\")\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfsMaD7zkHaR"
   },
   "source": [
    "### Ordinal Encoding layer (aka StringLookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9QA0j06kHaR"
   },
   "source": [
    "La forma de hacer el categórical encoding es unsar una capa de stringlookup que básicamente puede hacer ella el mapeo o se le puede dar (como en un ordinal de sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p415VlmbkHaR"
   },
   "source": [
    "Vamos a añadir las categóricas de dos formas, pero primero vamos a hacerles su ordinal encoding. El único pero es que hay que hacerlo feature a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ecgsRvZNkHaR"
   },
   "outputs": [],
   "source": [
    "X_train = train_set[numericas + categoricals].copy()\n",
    "#X_train[categoricals] = ordinalEncoding(train_set[categoricals])\n",
    "\n",
    "X_test = test_set[numericas + categoricals].copy()\n",
    "#X_test[categoricals] = ordinalEncoding(test_set[categoricals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pmdUzuzfkHaR"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "\n",
    "# no le damos valor, pero aquí el argumento vocabulary permite pasar una lista,\n",
    "# una tupla, un array, un tensor con los strings ordenados de forma que el primero recibira la clase 0, etc\n",
    "ordinalEncoding_layers = [tf.keras.layers.StringLookup() for cat in categoricals]                                               \n",
    "\n",
    "# ordinalEncoding.adapt(train_set[categoricals]) # Al igual que la capa de normalización hay que hacerle su fit en este caso el método adapt\n",
    "concat_layer = tf.keras.layers.Concatenate(axis=-1)\n",
    "hidden_layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "output_layer = tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "normalization_layer.adapt(train_set[numericas].to_numpy())\n",
    "# truco de programación para hacerlo en un única linea\n",
    "_ = [ordinalEncoding_layers[indice].adapt(train_set[col]) for indice,col in enumerate(categoricals)]\n",
    "\n",
    "earlyS = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "input_num = tf.keras.layers.Input(shape=(train_set[numericas].shape[1],))\n",
    "input_cats = [tf.keras.layers.Input(shape=(train_set[[col]].shape[1],), dtype = tf.string) for col in categoricals] # Importante decirle que entra una string\n",
    "normalized = normalization_layer(input_num)\n",
    "encoded = [ordinalEncoding_layers[i](input_cats[i]) for i in range(len(ordinalEncoding_layers))]\n",
    "concat = concat_layer([normalized] + encoded)\n",
    "hidden1 = hidden_layer1(concat)\n",
    "output = output_layer(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_num] + input_cats, outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BuyKU7GmkHaS"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-1),\\\n",
    "              metrics =[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0z38XXDkHaS",
    "outputId": "069f4a47-4ec3-4148-f428-91a0ce5b2e14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2485, 1), dtype=int64, numpy=\n",
       " array([[1],\n",
       "        [1],\n",
       "        [3],\n",
       "        ...,\n",
       "        [3],\n",
       "        [2],\n",
       "        [1]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(2485, 1), dtype=int64, numpy=\n",
       " array([[2],\n",
       "        [1],\n",
       "        [4],\n",
       "        ...,\n",
       "        [1],\n",
       "        [3],\n",
       "        [5]], dtype=int64)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida = tf.keras.Model(inputs=input_cats, outputs=encoded)\n",
    "salida([X_train[col] for col in categoricals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "k9u1SdZCkHaS",
    "outputId": "43a45015-5d52-40e8-cc67-c19a8934d629"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>Highly Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Highly Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>Moderately Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>Highly Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>Considerably Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>Highly Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Ineffective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Moderately Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Considerably Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Highly Effective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               effectiveness\n",
       "2686        Highly Effective\n",
       "1192        Highly Effective\n",
       "2738    Moderately Effective\n",
       "2780        Highly Effective\n",
       "1735  Considerably Effective\n",
       "...                      ...\n",
       "3092        Highly Effective\n",
       "1095             Ineffective\n",
       "1130    Moderately Effective\n",
       "1294  Considerably Effective\n",
       "860         Highly Effective\n",
       "\n",
       "[2485 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[categoricals[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Q22WO8xqkHaS"
   },
   "outputs": [],
   "source": [
    "entradas = [X_train[numericas]] + [X_train[col] for col in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxlDLwzxkHaS",
    "outputId": "54b9849f-418c-40a8-c8e0-84474a951494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 236ms/step - acc: 0.1875 - loss: 2.5168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_7', 'keras_tensor_8', 'keras_tensor_9']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.2683 - loss: 2.1325 - val_acc: 0.3139 - val_loss: 1.8725\n",
      "Epoch 2/100\n",
      "\u001b[1m57/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - acc: 0.4043 - loss: 1.7092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_7', 'keras_tensor_8', 'keras_tensor_9']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4051 - loss: 1.7058 - val_acc: 0.3622 - val_loss: 1.6759\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4336 - loss: 1.5413 - val_acc: 0.3843 - val_loss: 1.5912\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4479 - loss: 1.4548 - val_acc: 0.4064 - val_loss: 1.5400\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4580 - loss: 1.3973 - val_acc: 0.4044 - val_loss: 1.5046\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4729 - loss: 1.3540 - val_acc: 0.4185 - val_loss: 1.4715\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4863 - loss: 1.3159 - val_acc: 0.4185 - val_loss: 1.4418\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4885 - loss: 1.2836 - val_acc: 0.4266 - val_loss: 1.4020\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4875 - loss: 1.2528 - val_acc: 0.4245 - val_loss: 1.3865\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4927 - loss: 1.2274 - val_acc: 0.4447 - val_loss: 1.3430\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5033 - loss: 1.1982 - val_acc: 0.4567 - val_loss: 1.3174\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5158 - loss: 1.1757 - val_acc: 0.4688 - val_loss: 1.2911\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5159 - loss: 1.1554 - val_acc: 0.4588 - val_loss: 1.2738\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5240 - loss: 1.1406 - val_acc: 0.4769 - val_loss: 1.2374\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5342 - loss: 1.1173 - val_acc: 0.4748 - val_loss: 1.2180\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5418 - loss: 1.0999 - val_acc: 0.4829 - val_loss: 1.1915\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5447 - loss: 1.0814 - val_acc: 0.4829 - val_loss: 1.1720\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5472 - loss: 1.0623 - val_acc: 0.4990 - val_loss: 1.1471\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5550 - loss: 1.0431 - val_acc: 0.5111 - val_loss: 1.1296\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5739 - loss: 1.0275 - val_acc: 0.5131 - val_loss: 1.1111\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5739 - loss: 1.0129 - val_acc: 0.5231 - val_loss: 1.0901\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5897 - loss: 0.9958 - val_acc: 0.5352 - val_loss: 1.0647\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5916 - loss: 0.9850 - val_acc: 0.5513 - val_loss: 1.0482\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6035 - loss: 0.9678 - val_acc: 0.5473 - val_loss: 1.0519\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6140 - loss: 0.9539 - val_acc: 0.5453 - val_loss: 1.0462\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6181 - loss: 0.9441 - val_acc: 0.5392 - val_loss: 1.0424\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6237 - loss: 0.9377 - val_acc: 0.5594 - val_loss: 1.0189\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6361 - loss: 0.9192 - val_acc: 0.5634 - val_loss: 1.0210\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6509 - loss: 0.9094 - val_acc: 0.5674 - val_loss: 1.0100\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6602 - loss: 0.8944 - val_acc: 0.5875 - val_loss: 0.9854\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6707 - loss: 0.8693 - val_acc: 0.6097 - val_loss: 0.9497\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6771 - loss: 0.8629 - val_acc: 0.6358 - val_loss: 0.9090\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6819 - loss: 0.8478 - val_acc: 0.6499 - val_loss: 0.9085\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6951 - loss: 0.8287 - val_acc: 0.6459 - val_loss: 0.8924\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7000 - loss: 0.8234 - val_acc: 0.6700 - val_loss: 0.8696\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7064 - loss: 0.8024 - val_acc: 0.6942 - val_loss: 0.8248\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7035 - loss: 0.7974 - val_acc: 0.6821 - val_loss: 0.8362\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7166 - loss: 0.7807 - val_acc: 0.6881 - val_loss: 0.8257\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7271 - loss: 0.7672 - val_acc: 0.7143 - val_loss: 0.7906\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7302 - loss: 0.7452 - val_acc: 0.7183 - val_loss: 0.7978\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7295 - loss: 0.7533 - val_acc: 0.7123 - val_loss: 0.7952\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7395 - loss: 0.7429 - val_acc: 0.7304 - val_loss: 0.7770\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7443 - loss: 0.7309 - val_acc: 0.7465 - val_loss: 0.7516\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7592 - loss: 0.7092 - val_acc: 0.7525 - val_loss: 0.7561\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7621 - loss: 0.7049 - val_acc: 0.7606 - val_loss: 0.7315\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7676 - loss: 0.6969 - val_acc: 0.7505 - val_loss: 0.7359\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7747 - loss: 0.6789 - val_acc: 0.7646 - val_loss: 0.7145\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7640 - loss: 0.6941 - val_acc: 0.7706 - val_loss: 0.7112\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7921 - loss: 0.6540 - val_acc: 0.7726 - val_loss: 0.6993\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7828 - loss: 0.6512 - val_acc: 0.7465 - val_loss: 0.7173\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8003 - loss: 0.6427 - val_acc: 0.7726 - val_loss: 0.6873\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7881 - loss: 0.6412 - val_acc: 0.7807 - val_loss: 0.6740\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7951 - loss: 0.6324 - val_acc: 0.7847 - val_loss: 0.6764\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7874 - loss: 0.6336 - val_acc: 0.7928 - val_loss: 0.6539\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8167 - loss: 0.6031 - val_acc: 0.7948 - val_loss: 0.6526\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8017 - loss: 0.6122 - val_acc: 0.8028 - val_loss: 0.6289\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8254 - loss: 0.5755 - val_acc: 0.8028 - val_loss: 0.6325\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8074 - loss: 0.5844 - val_acc: 0.8109 - val_loss: 0.6150\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8263 - loss: 0.5640 - val_acc: 0.8089 - val_loss: 0.6197\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8236 - loss: 0.5726 - val_acc: 0.8129 - val_loss: 0.6019\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8412 - loss: 0.5435 - val_acc: 0.8229 - val_loss: 0.5918\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8318 - loss: 0.5538 - val_acc: 0.8229 - val_loss: 0.5857\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8369 - loss: 0.5412 - val_acc: 0.8229 - val_loss: 0.5796\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8389 - loss: 0.5333 - val_acc: 0.8209 - val_loss: 0.5879\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8371 - loss: 0.5368 - val_acc: 0.8270 - val_loss: 0.5749\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8475 - loss: 0.5201 - val_acc: 0.8229 - val_loss: 0.5767\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8443 - loss: 0.5154 - val_acc: 0.8270 - val_loss: 0.5624\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8533 - loss: 0.5057 - val_acc: 0.8350 - val_loss: 0.5613\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8481 - loss: 0.5110 - val_acc: 0.8310 - val_loss: 0.5485\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8604 - loss: 0.4778 - val_acc: 0.8370 - val_loss: 0.5389\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8617 - loss: 0.4684 - val_acc: 0.8370 - val_loss: 0.5400\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8007 - loss: 0.5991 - val_acc: 0.8451 - val_loss: 0.5308\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8684 - loss: 0.4691 - val_acc: 0.8431 - val_loss: 0.5382\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8733 - loss: 0.4510 - val_acc: 0.8451 - val_loss: 0.5258\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8844 - loss: 0.4080 - val_acc: 0.8451 - val_loss: 0.5123\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7782 - loss: 0.6743 - val_acc: 0.8511 - val_loss: 0.5087\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8856 - loss: 0.4033 - val_acc: 0.8531 - val_loss: 0.5057\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8863 - loss: 0.3819 - val_acc: 0.8592 - val_loss: 0.4914\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7789 - loss: 0.6668 - val_acc: 0.8471 - val_loss: 0.4887\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8986 - loss: 0.3617 - val_acc: 0.8571 - val_loss: 0.4960\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7808 - loss: 0.6542 - val_acc: 0.8451 - val_loss: 0.4888\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9044 - loss: 0.3485 - val_acc: 0.8652 - val_loss: 0.4861\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7989 - loss: 0.5748 - val_acc: 0.8592 - val_loss: 0.4704\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9100 - loss: 0.3261 - val_acc: 0.8632 - val_loss: 0.4695\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7969 - loss: 0.6204 - val_acc: 0.8551 - val_loss: 0.4761\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9181 - loss: 0.3158 - val_acc: 0.8773 - val_loss: 0.4631\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7949 - loss: 0.6251 - val_acc: 0.8712 - val_loss: 0.4424\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9186 - loss: 0.3014 - val_acc: 0.8753 - val_loss: 0.4557\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7916 - loss: 0.6405 - val_acc: 0.8712 - val_loss: 0.4376\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9229 - loss: 0.2913 - val_acc: 0.8793 - val_loss: 0.4459\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7930 - loss: 0.6379 - val_acc: 0.8692 - val_loss: 0.4315\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9219 - loss: 0.2911 - val_acc: 0.8813 - val_loss: 0.4360\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7919 - loss: 0.6214 - val_acc: 0.8793 - val_loss: 0.4152\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9280 - loss: 0.2739 - val_acc: 0.8833 - val_loss: 0.4215\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7916 - loss: 0.6529 - val_acc: 0.8833 - val_loss: 0.4074\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9306 - loss: 0.2631 - val_acc: 0.8853 - val_loss: 0.4158\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7991 - loss: 0.6187 - val_acc: 0.8853 - val_loss: 0.3969\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9312 - loss: 0.2566 - val_acc: 0.8893 - val_loss: 0.4084\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8123 - loss: 0.5921 - val_acc: 0.8833 - val_loss: 0.3899\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9297 - loss: 0.2593 - val_acc: 0.8893 - val_loss: 0.3854\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(entradas, y_num, validation_split=0.2, epochs=100, callbacks= earlyS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxxx-vEokHaS",
    "outputId": "ca31eeab-b890-43c4-b757-881c44bc2359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9234 - loss: 0.3104 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33659836649894714, 0.9067524075508118]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada_test = [X_test[numericas]] + [X_test[col] for col in categoricals]\n",
    "model.evaluate(entrada_test, test_set[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuiz4EdwkHaS"
   },
   "source": [
    "Algo hemos mejorado con esta categorización, ¿no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c86TeVKkHaT",
    "outputId": "f11ce8a6-37cf-4526-c2a8-93c33f9a8686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_7', 'keras_tensor_8', 'keras_tensor_9']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred  = [np.argmax(pred) for pred in model.predict(entrada_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o80TJArGkHaT",
    "outputId": "c7052594-69e4-4684-a9cc-dbd165560151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        62\n",
      "           1       1.00      0.38      0.55        16\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.33      0.83      0.48        18\n",
      "           4       0.69      0.67      0.68        27\n",
      "           5       0.91      0.76      0.83        38\n",
      "           6       0.95      0.95      0.95        83\n",
      "           7       0.98      1.00      0.99        94\n",
      "           8       1.00      1.00      1.00       110\n",
      "           9       1.00      1.00      1.00       151\n",
      "\n",
      "    accuracy                           0.91       622\n",
      "   macro avg       0.77      0.76      0.74       622\n",
      "weighted avg       0.90      0.91      0.90       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set[target], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RXGtqtjkHaT"
   },
   "source": [
    "#### Onehotencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3thQyowkHaT"
   },
   "source": [
    "Pero podemos hacer el onehot encoding de una vez configurando la StringLookup layer debidamente.  Además ahora usaremos la functional API para incluir la capa dentro del modelo (y no tener que hacer la conversión por fuera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8ZG0nOMNkHaT"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "# no le damos valor, pero aquí el argumento vocabulary permite pasar una lista,\n",
    "# una tupla, un array, un tensor con los strings ordenados de forma que el primero recibira la clase 0, etc\n",
    "ordinalEncoding_layers = [tf.keras.layers.StringLookup(output_mode=\"one_hot\") for cat in categoricals]                                              \n",
    "\n",
    "# ordinalEncoding.adapt(train_set[categoricals]) # Al igual que la capa de normalización hay que hacerle su fit en este caso el método adapt\n",
    "concat_layer = tf.keras.layers.Concatenate(axis = -1)\n",
    "hidden_layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "output_layer = tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "normalization_layer.adapt(train_set[numericas].to_numpy())\n",
    "_ = [ordinalEncoding_layers[indice].adapt(train_set[col]) for indice,col in enumerate(categoricals)]\n",
    "\n",
    "earlyS = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights= True)\n",
    "input_num = tf.keras.layers.Input(shape=(train_set[numericas].shape[1],))\n",
    "input_cats = [tf.keras.layers.Input(shape=(train_set[[col]].shape[1],), dtype = tf.string) for col in categoricals] # Importante decirle que entra una string\n",
    "normalized = normalization_layer(input_num)\n",
    "encoded = [ordinalEncoding_layers[i](input_cats[i]) for i in range(len(ordinalEncoding_layers))]\n",
    "concat = concat_layer([normalized] + encoded)\n",
    "hidden1 = hidden_layer1(concat)\n",
    "output = output_layer(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_num] + input_cats, outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIysOD6SkHaT",
    "outputId": "72d8bde7-cea5-4b6f-dfd4-28287db26cc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2485, 6), dtype=int64, numpy=\n",
       " array([[0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(2485, 6), dtype=int64, numpy=\n",
       " array([[0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1]], dtype=int64)>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida = tf.keras.Model(inputs = input_cats, outputs = encoded)\n",
    "salida([X_train[col] for col in categoricals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "XS0bE3O5kHaT",
    "outputId": "d3f46408-4c00-40bb-a884-394fa27154fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sideEffects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>No Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Mild Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>Severe Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>Moderate Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>No Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>Mild Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Severe Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Mild Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Moderate Side Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Extremely Severe Side Effects</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sideEffects\n",
       "2686                No Side Effects\n",
       "1192              Mild Side Effects\n",
       "2738            Severe Side Effects\n",
       "2780          Moderate Side Effects\n",
       "1735                No Side Effects\n",
       "...                             ...\n",
       "3092              Mild Side Effects\n",
       "1095            Severe Side Effects\n",
       "1130              Mild Side Effects\n",
       "1294          Moderate Side Effects\n",
       "860   Extremely Severe Side Effects\n",
       "\n",
       "[2485 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[categoricals[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "BsD6b3l2kHaU"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-1),\n",
    "              metrics =[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "bZytZjtpkHaU"
   },
   "outputs": [],
   "source": [
    "entradas = [X_train[numericas]] + [X_train[col] for col in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFAwEvLhkHaU",
    "outputId": "c2bb00de-5d4b-4a63-aa2d-6eb7c80ad278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_16', 'keras_tensor_17', 'keras_tensor_18']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3311 - loss: 1.9715 - val_acc: 0.3823 - val_loss: 1.6460\n",
      "Epoch 2/100\n",
      "\u001b[1m 2/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4531 - loss: 1.51400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_16', 'keras_tensor_17', 'keras_tensor_18']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.4508 - loss: 1.5144 - val_acc: 0.3903 - val_loss: 1.5107\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4699 - loss: 1.3812 - val_acc: 0.4125 - val_loss: 1.4524\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4853 - loss: 1.3160 - val_acc: 0.4245 - val_loss: 1.4177\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4975 - loss: 1.2761 - val_acc: 0.4427 - val_loss: 1.3946\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5033 - loss: 1.2466 - val_acc: 0.4427 - val_loss: 1.3734\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5084 - loss: 1.2196 - val_acc: 0.4487 - val_loss: 1.3537\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5147 - loss: 1.1944 - val_acc: 0.4588 - val_loss: 1.3347\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5249 - loss: 1.1693 - val_acc: 0.4588 - val_loss: 1.3188\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5302 - loss: 1.1446 - val_acc: 0.4748 - val_loss: 1.2978\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5367 - loss: 1.1186 - val_acc: 0.4849 - val_loss: 1.2781\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5520 - loss: 1.0925 - val_acc: 0.4950 - val_loss: 1.2539\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5604 - loss: 1.0642 - val_acc: 0.5050 - val_loss: 1.2401\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5714 - loss: 1.0370 - val_acc: 0.5091 - val_loss: 1.2174\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5807 - loss: 1.0082 - val_acc: 0.5131 - val_loss: 1.1896\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5971 - loss: 0.9785 - val_acc: 0.5252 - val_loss: 1.1754\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6144 - loss: 0.9501 - val_acc: 0.5252 - val_loss: 1.1482\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6253 - loss: 0.9207 - val_acc: 0.5433 - val_loss: 1.1220\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6408 - loss: 0.8925 - val_acc: 0.5513 - val_loss: 1.0985\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6560 - loss: 0.8645 - val_acc: 0.5674 - val_loss: 1.0646\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6730 - loss: 0.8370 - val_acc: 0.5795 - val_loss: 1.0438\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.6838 - loss: 0.8108 - val_acc: 0.5976 - val_loss: 1.0121\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6989 - loss: 0.7849 - val_acc: 0.6137 - val_loss: 0.9751\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7210 - loss: 0.7594 - val_acc: 0.6217 - val_loss: 0.9483\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7402 - loss: 0.7357 - val_acc: 0.6298 - val_loss: 0.9145\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7476 - loss: 0.7120 - val_acc: 0.6419 - val_loss: 0.8882\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.7674 - loss: 0.6897 - val_acc: 0.6660 - val_loss: 0.8547\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7830 - loss: 0.6679 - val_acc: 0.6700 - val_loss: 0.8314\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7958 - loss: 0.6473 - val_acc: 0.6901 - val_loss: 0.8038\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8047 - loss: 0.6270 - val_acc: 0.7183 - val_loss: 0.7789\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8109 - loss: 0.6080 - val_acc: 0.7284 - val_loss: 0.7555\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8190 - loss: 0.5894 - val_acc: 0.7344 - val_loss: 0.7362\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8251 - loss: 0.5720 - val_acc: 0.7465 - val_loss: 0.7145\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8307 - loss: 0.5549 - val_acc: 0.7525 - val_loss: 0.6952\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8416 - loss: 0.5385 - val_acc: 0.7686 - val_loss: 0.6793\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8486 - loss: 0.5230 - val_acc: 0.7827 - val_loss: 0.6613\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.8598 - loss: 0.5083 - val_acc: 0.7887 - val_loss: 0.6425\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8680 - loss: 0.4930 - val_acc: 0.7887 - val_loss: 0.6297\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8753 - loss: 0.4795 - val_acc: 0.8008 - val_loss: 0.6155\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8848 - loss: 0.4660 - val_acc: 0.8089 - val_loss: 0.6011\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8878 - loss: 0.4531 - val_acc: 0.8109 - val_loss: 0.5873\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8944 - loss: 0.4407 - val_acc: 0.8149 - val_loss: 0.5748\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8968 - loss: 0.4288 - val_acc: 0.8149 - val_loss: 0.5629\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8994 - loss: 0.4172 - val_acc: 0.8209 - val_loss: 0.5510\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9031 - loss: 0.4062 - val_acc: 0.8270 - val_loss: 0.5396\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9064 - loss: 0.3954 - val_acc: 0.8290 - val_loss: 0.5267\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9079 - loss: 0.3850 - val_acc: 0.8330 - val_loss: 0.5188\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9132 - loss: 0.3751 - val_acc: 0.8350 - val_loss: 0.5090\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9150 - loss: 0.3657 - val_acc: 0.8390 - val_loss: 0.4992\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9190 - loss: 0.3563 - val_acc: 0.8390 - val_loss: 0.4896\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9188 - loss: 0.3474 - val_acc: 0.8471 - val_loss: 0.4799\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9244 - loss: 0.3387 - val_acc: 0.8511 - val_loss: 0.4709\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9284 - loss: 0.3305 - val_acc: 0.8531 - val_loss: 0.4624\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9309 - loss: 0.3224 - val_acc: 0.8592 - val_loss: 0.4547\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9361 - loss: 0.3148 - val_acc: 0.8612 - val_loss: 0.4471\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9373 - loss: 0.3074 - val_acc: 0.8652 - val_loss: 0.4401\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9408 - loss: 0.3001 - val_acc: 0.8652 - val_loss: 0.4328\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9431 - loss: 0.2938 - val_acc: 0.8652 - val_loss: 0.4260\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9439 - loss: 0.2869 - val_acc: 0.8712 - val_loss: 0.4195\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9465 - loss: 0.2805 - val_acc: 0.8712 - val_loss: 0.4131\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9471 - loss: 0.2744 - val_acc: 0.8793 - val_loss: 0.4069\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9475 - loss: 0.2685 - val_acc: 0.8773 - val_loss: 0.4001\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9538 - loss: 0.2627 - val_acc: 0.8793 - val_loss: 0.3945\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9545 - loss: 0.2571 - val_acc: 0.8833 - val_loss: 0.3900\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9553 - loss: 0.2519 - val_acc: 0.8853 - val_loss: 0.3835\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9553 - loss: 0.2466 - val_acc: 0.8873 - val_loss: 0.3793\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9560 - loss: 0.2417 - val_acc: 0.8873 - val_loss: 0.3736\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9560 - loss: 0.2366 - val_acc: 0.8873 - val_loss: 0.3685\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9557 - loss: 0.2319 - val_acc: 0.8893 - val_loss: 0.3646\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9557 - loss: 0.2273 - val_acc: 0.8913 - val_loss: 0.3593\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9573 - loss: 0.2227 - val_acc: 0.8934 - val_loss: 0.3551\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9576 - loss: 0.2185 - val_acc: 0.8934 - val_loss: 0.3513\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9586 - loss: 0.2143 - val_acc: 0.8974 - val_loss: 0.3464\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9589 - loss: 0.2103 - val_acc: 0.8994 - val_loss: 0.3420\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9589 - loss: 0.2064 - val_acc: 0.9014 - val_loss: 0.3373\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9610 - loss: 0.2024 - val_acc: 0.9034 - val_loss: 0.3337\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9628 - loss: 0.1988 - val_acc: 0.9054 - val_loss: 0.3302\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9642 - loss: 0.1952 - val_acc: 0.9074 - val_loss: 0.3260\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9645 - loss: 0.1916 - val_acc: 0.9095 - val_loss: 0.3223\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9651 - loss: 0.1883 - val_acc: 0.9095 - val_loss: 0.3187\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9667 - loss: 0.1847 - val_acc: 0.9095 - val_loss: 0.3153\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9682 - loss: 0.1816 - val_acc: 0.9095 - val_loss: 0.3124\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9684 - loss: 0.1785 - val_acc: 0.9095 - val_loss: 0.3087\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9689 - loss: 0.1754 - val_acc: 0.9095 - val_loss: 0.3057\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9713 - loss: 0.1724 - val_acc: 0.9095 - val_loss: 0.3024\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9721 - loss: 0.1694 - val_acc: 0.9095 - val_loss: 0.2998\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9746 - loss: 0.1666 - val_acc: 0.9095 - val_loss: 0.2969\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9768 - loss: 0.1636 - val_acc: 0.9115 - val_loss: 0.2944\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9776 - loss: 0.1609 - val_acc: 0.9115 - val_loss: 0.2915\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9776 - loss: 0.1585 - val_acc: 0.9115 - val_loss: 0.2880\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9782 - loss: 0.1558 - val_acc: 0.9115 - val_loss: 0.2861\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9781 - loss: 0.1536 - val_acc: 0.9115 - val_loss: 0.2833\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9795 - loss: 0.1508 - val_acc: 0.9115 - val_loss: 0.2806\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9795 - loss: 0.1483 - val_acc: 0.9135 - val_loss: 0.2780\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9808 - loss: 0.1462 - val_acc: 0.9155 - val_loss: 0.2750\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9814 - loss: 0.1436 - val_acc: 0.9155 - val_loss: 0.2729\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9814 - loss: 0.1413 - val_acc: 0.9175 - val_loss: 0.2702\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9821 - loss: 0.1391 - val_acc: 0.9155 - val_loss: 0.2677\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9826 - loss: 0.1369 - val_acc: 0.9175 - val_loss: 0.2655\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.9829 - loss: 0.1347 - val_acc: 0.9175 - val_loss: 0.2637\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(entradas, y_num, validation_split=0.2, epochs=100, callbacks=earlyS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43YDM0eLkHaU",
    "outputId": "6445d914-b20d-4773-b11d-9c6f9a9ae32f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9421 - loss: 0.2209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23860207200050354, 0.9340835809707642]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(entrada_test,test_set[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpB4vF76kHaU"
   },
   "source": [
    "Un poco mejor que con el ordinal, pero sin pasarse y además hay que ver el impacto del desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiCNsH6nkHaU",
    "outputId": "f9198aca-3c54-4ecf-e774-59346023acd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_16', 'keras_tensor_17', 'keras_tensor_18']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred  = [np.argmax(pred) for pred in model.predict(entrada_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZQqEDo6kHaU",
    "outputId": "79b22dc4-4b29-42da-f77b-48066c26a5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        62\n",
      "           1       1.00      0.38      0.55        16\n",
      "           2       0.61      0.83      0.70        23\n",
      "           3       0.70      0.39      0.50        18\n",
      "           4       0.57      1.00      0.73        27\n",
      "           5       0.89      0.66      0.76        38\n",
      "           6       0.98      0.96      0.97        83\n",
      "           7       1.00      1.00      1.00        94\n",
      "           8       1.00      1.00      1.00       110\n",
      "           9       1.00      1.00      1.00       151\n",
      "\n",
      "    accuracy                           0.93       622\n",
      "   macro avg       0.87      0.82      0.82       622\n",
      "weighted avg       0.95      0.93      0.93       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set[target], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9dUgls6kHaU"
   },
   "source": [
    "Se nos va de nuevo a la clase mayoritaria. En la siguiente sesión añadiremos la vectorización de las features de texto y te enseñare a configurar el class_weight para aliviar (no siempre mucho) el efecto del desbalanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzPva7IqkHaV"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJz6MroxkHaV"
   },
   "source": [
    "Primero vamos a mostrar rápidamente como funciona la capa de vectorizacion de texto de keras y luego aplicaremos el proceso completo (recuerda que hay que limpiar el texto y tokenizarlo antes de hacer su vectorización). Vamos con la(s) capa(s) de vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilxdj5A2kHaV"
   },
   "source": [
    "## Capas de Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK7u7OKMkHaV"
   },
   "source": [
    "El equivalente al CountVectorizer y al TfidfVectorizer de sklearn es la capa TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "EEFYwnwokHaV"
   },
   "outputs": [],
   "source": [
    " # output_mode=\"count\" -> Countvectorizer\n",
    "text_vec_layer_count = tf.keras.layers.TextVectorization(output_mode=\"count\")\n",
    "\n",
    "text_vec_layer_count.adapt(train_set[[\"sideEffectsReview\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ce3i-5-HkHaV",
    "outputId": "9530f5b3-8920-44ca-e4f2-5a7d647a4bc1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', 'i', 'the', 'and', 'to', 'a', 'of', 'my', 'it', 'was']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_count.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "313X7oT_kHaV",
    "outputId": "ba1187b5-f1ef-4461-cf39-52a5d8675a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['redness, dryness, breakdown of skin']\n"
     ]
    }
   ],
   "source": [
    "texto = train_set[\"sideEffectsReview\"][2:3].values\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "z3LY5xJVkHaV"
   },
   "outputs": [],
   "source": [
    "# output_mode=\"tf_idf\" --> TfIdfVectorizer, existe un tercer modo (el que viene por defecto que veremos un poco más adelante)\n",
    "text_vec_layer_tfidf = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")\n",
    "text_vec_layer_tfidf.adapt(train_set[\"sideEffectsReview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CC2Cm-6kHaW",
    "outputId": "a504d814-5681-4fa5-8184-545899a45cca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2485, 6564), dtype=int64, numpy=\n",
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 8, 3, ..., 0, 0, 0],\n",
       "       [0, 1, 2, ..., 0, 0, 0]], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = text_vec_layer_count(train_set[\"sideEffectsReview\"])\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "CfTCetjLkHaW",
    "outputId": "da5d2338-63e0-449c-ee11-576d07fb0295",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[UNK]</th>\n",
       "      <th>i</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>a</th>\n",
       "      <th>of</th>\n",
       "      <th>my</th>\n",
       "      <th>it</th>\n",
       "      <th>was</th>\n",
       "      <th>...</th>\n",
       "      <th>10142008</th>\n",
       "      <th>1014</th>\n",
       "      <th>1012</th>\n",
       "      <th>100mgthe</th>\n",
       "      <th>100mgs</th>\n",
       "      <th>100mgdoses</th>\n",
       "      <th>100110</th>\n",
       "      <th>1000mg</th>\n",
       "      <th>10000</th>\n",
       "      <th>072009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 6564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [UNK]  i  the  and  to  a  of  my  it  was  ...  10142008  1014  1012  \\\n",
       "0         0  1    0    0   0  0   1   0   0    0  ...         0     0     0   \n",
       "1         0  0    0    0   0  1   0   0   0    0  ...         0     0     0   \n",
       "2         0  0    0    0   0  0   1   0   0    0  ...         0     0     0   \n",
       "3         0  2    3    2   0  0   0   2   0    0  ...         0     0     0   \n",
       "4         0  4    7    3   3  0   2   0   2    2  ...         0     0     0   \n",
       "...     ... ..  ...  ...  .. ..  ..  ..  ..  ...  ...       ...   ...   ...   \n",
       "2480      0  3    5    1   0  0   0   0   1    2  ...         0     0     0   \n",
       "2481      0  0    0    0   0  0   0   0   0    0  ...         0     0     0   \n",
       "2482      0  1    0    1   0  1   0   0   0    0  ...         0     0     0   \n",
       "2483      0  8    3    1   7  3   3   2   1    3  ...         0     0     0   \n",
       "2484      0  1    2    2   2  2   0   0   0    1  ...         0     0     0   \n",
       "\n",
       "      100mgthe  100mgs  100mgdoses  100110  1000mg  10000  072009  \n",
       "0            0       0           0       0       0      0       0  \n",
       "1            0       0           0       0       0      0       0  \n",
       "2            0       0           0       0       0      0       0  \n",
       "3            0       0           0       0       0      0       0  \n",
       "4            0       0           0       0       0      0       0  \n",
       "...        ...     ...         ...     ...     ...    ...     ...  \n",
       "2480         0       0           0       0       0      0       0  \n",
       "2481         0       0           0       0       0      0       0  \n",
       "2482         0       0           0       0       0      0       0  \n",
       "2483         0       0           0       0       0      0       0  \n",
       "2484         0       0           0       0       0      0       0  \n",
       "\n",
       "[2485 rows x 6564 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors = pd.DataFrame(vectors.numpy(),\n",
    "                          columns= text_vec_layer_count.get_vocabulary())\n",
    "df_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "wRV3yt_mkHaW",
    "outputId": "06ac4c4c-1e81-4af1-9604-1a2a50ebb6a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had no real side effects unless you consider lack of fear or worry one.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[0][\"sideEffectsReview\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "xmaPcLDnkHaW",
    "outputId": "3453b40d-2836-4c23-d275-3f77f56ea5ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i           1\n",
       "of          1\n",
       "side        1\n",
       "effects     1\n",
       "had         1\n",
       "no          1\n",
       "or          1\n",
       "you         1\n",
       "one         1\n",
       "lack        1\n",
       "real        1\n",
       "unless      1\n",
       "consider    1\n",
       "fear        1\n",
       "worry       1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors.T[df_vectors.T[0] != 0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwqli-cEkHaW"
   },
   "source": [
    "#### Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YzRupqNkHaW"
   },
   "source": [
    "Tendremos que hacer la normalización/limpieza del texto y \"tokenizacion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHOpk1iTmUSM",
    "outputId": "488ca925-03d9-4699-83fc-56ae232869ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descargar las stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "AczWvRhrkHaX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Lander\\AppData\\Local\\Temp\\ipykernel_8912\\2802507076.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  replace_no_space = \"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\"\n",
      "C:\\Users\\Lander\\AppData\\Local\\Temp\\ipykernel_8912\\2802507076.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  replace_with_space = \"(<br \\s*/><br\\s*/>)|(\\-)|(\\/)\"\n"
     ]
    }
   ],
   "source": [
    "# Rescatando la que hicimos para la IMDB Reviews\n",
    "\n",
    "replace_no_space = \"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\"\n",
    "REPLACE_NO_SPACE = re.compile(replace_no_space)\n",
    "replace_with_space = \"(<br \\s*/><br\\s*/>)|(\\-)|(\\/)\"\n",
    "REPLACE_WITH_SPACE = re.compile(replace_with_space)\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "dictionary = stopwords.words(\"english\")\n",
    "\n",
    "def clean(row):\n",
    "    # Limpio signos y convierto a minúsculas\n",
    "    dato = REPLACE_NO_SPACE.sub(NO_SPACE, row.lower())\n",
    "    # Convierto los retornos de carro <br /><br /> en espacios y los guiones (\"-\")\n",
    "    dato = REPLACE_WITH_SPACE.sub(SPACE, dato)\n",
    "    # Quito cualquier link\n",
    "    dato = \" \".join([word for word in dato.split() if \"http\" not in word])\n",
    "    # Quito los stopwords\n",
    "    dato = \" \".join([word for word in dato.split(\" \") if word not in dictionary])\n",
    "    return dato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmt-vBkgkHaX"
   },
   "source": [
    "Antes, identificamos las features que son texto natural:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFWeI7JFkHaX",
    "outputId": "4f1978b5-f482-44dd-fa49-bf37cc48d499"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benefitsReview', 'sideEffectsReview', 'commentsReview']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feats = [col for col in train_set.columns if \"Review\" in col and \"wc\" not in col]\n",
    "text_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RI2GOn6kHaX"
   },
   "source": [
    "\n",
    "Y ahora aplicamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "bYZXAbrUkHaX"
   },
   "outputs": [],
   "source": [
    "for col in text_feats:\n",
    "    train_set[col] = train_set[col].apply(clean)\n",
    "    test_set[col] = test_set[col].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "o4NBprf6kHaX",
    "outputId": "a7b2a374-4f63-4bbc-b047-c35e9da0b941"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "      <th>benefitsReview_wc</th>\n",
       "      <th>sideEffectsReview_wc</th>\n",
       "      <th>commentsReview_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>zoloft</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>becoming normal functioning individual helped ...</td>\n",
       "      <td>real side effects unless consider lack fear wo...</td>\n",
       "      <td>taken daily</td>\n",
       "      <td>135166</td>\n",
       "      <td>335.0</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>adipex-p</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>to lose 30 pounds</td>\n",
       "      <td>bmi rating time get taken care goes beyond tak...</td>\n",
       "      <td>jittery sometimes euphoric tired cant sleep zone</td>\n",
       "      <td>last results months adipex p lost pounds gaine...</td>\n",
       "      <td>739564</td>\n",
       "      <td>939.0</td>\n",
       "      <td>163</td>\n",
       "      <td>10</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>tri-luma</td>\n",
       "      <td>7</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>hyperpigmentation</td>\n",
       "      <td>lightening acne scars</td>\n",
       "      <td>redness dryness breakdown skin</td>\n",
       "      <td>topical compound used reduce hyperpigmentation...</td>\n",
       "      <td>683247</td>\n",
       "      <td>843.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>yasmin</td>\n",
       "      <td>2</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>birth control</td>\n",
       "      <td>chance pregancy lost percent libido skin clear...</td>\n",
       "      <td>libido ever breasts hurt like got bigger itche...</td>\n",
       "      <td>given prevent pregnancy going i'd rather child...</td>\n",
       "      <td>222295</td>\n",
       "      <td>282.0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>requip</td>\n",
       "      <td>7</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>restless leg syndrome</td>\n",
       "      <td>took medication treat restless leg syndrome ef...</td>\n",
       "      <td>need take time went experienced augmentation r...</td>\n",
       "      <td>took one milligram night treat symtoms restles...</td>\n",
       "      <td>344748</td>\n",
       "      <td>505.0</td>\n",
       "      <td>93</td>\n",
       "      <td>69</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>zyrtec</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>atopic eczema</td>\n",
       "      <td>drug effective counteracting severe itching ca...</td>\n",
       "      <td>felt slightly tired taking zyrtec however seve...</td>\n",
       "      <td>non prescription drug took experiencing severe...</td>\n",
       "      <td>156028</td>\n",
       "      <td>356.0</td>\n",
       "      <td>74</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>neurontin</td>\n",
       "      <td>0</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>all over and various type pain</td>\n",
       "      <td>value</td>\n",
       "      <td>nausea extreme sleepinesssevere headache jitte...</td>\n",
       "      <td>day one felt negative side effects taking seco...</td>\n",
       "      <td>317886</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>wellbutrin</td>\n",
       "      <td>6</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>depression</td>\n",
       "      <td>experienced less depression increased libido p...</td>\n",
       "      <td>dry mouth eyes drug decreased effectiveness la...</td>\n",
       "      <td>prescribed mg per day taken much mg per day li...</td>\n",
       "      <td>556187</td>\n",
       "      <td>696.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>wellbutrin</td>\n",
       "      <td>2</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>stop smoking</td>\n",
       "      <td>treatment effective reducing appetite smoking ...</td>\n",
       "      <td>began notice nothing seemed important also see...</td>\n",
       "      <td>taking bupropion aide break smoking habit also...</td>\n",
       "      <td>728338</td>\n",
       "      <td>789.0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>accutane</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Extremely Severe Side Effects</td>\n",
       "      <td>cystic acne</td>\n",
       "      <td>drug cleared skin even reduced redness scarrin...</td>\n",
       "      <td>severe sexual side effects began months trial ...</td>\n",
       "      <td>treatment began two mg tablets twice day reduc...</td>\n",
       "      <td>154819</td>\n",
       "      <td>255.0</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     urlDrugName  rating           effectiveness  \\\n",
       "2686      zoloft       9        Highly Effective   \n",
       "1192    adipex-p       9        Highly Effective   \n",
       "2738    tri-luma       7    Moderately Effective   \n",
       "2780      yasmin       2        Highly Effective   \n",
       "1735      requip       7  Considerably Effective   \n",
       "...          ...     ...                     ...   \n",
       "3092      zyrtec       9        Highly Effective   \n",
       "1095   neurontin       0             Ineffective   \n",
       "1130  wellbutrin       6    Moderately Effective   \n",
       "1294  wellbutrin       2  Considerably Effective   \n",
       "860     accutane       4        Highly Effective   \n",
       "\n",
       "                        sideEffects                       condition  \\\n",
       "2686                No Side Effects                         anxiety   \n",
       "1192              Mild Side Effects               to lose 30 pounds   \n",
       "2738            Severe Side Effects               hyperpigmentation   \n",
       "2780          Moderate Side Effects                   birth control   \n",
       "1735                No Side Effects           restless leg syndrome   \n",
       "...                             ...                             ...   \n",
       "3092              Mild Side Effects                   atopic eczema   \n",
       "1095            Severe Side Effects  all over and various type pain   \n",
       "1130              Mild Side Effects                      depression   \n",
       "1294          Moderate Side Effects                    stop smoking   \n",
       "860   Extremely Severe Side Effects                     cystic acne   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "2686  becoming normal functioning individual helped ...   \n",
       "1192  bmi rating time get taken care goes beyond tak...   \n",
       "2738                              lightening acne scars   \n",
       "2780  chance pregancy lost percent libido skin clear...   \n",
       "1735  took medication treat restless leg syndrome ef...   \n",
       "...                                                 ...   \n",
       "3092  drug effective counteracting severe itching ca...   \n",
       "1095                                              value   \n",
       "1130  experienced less depression increased libido p...   \n",
       "1294  treatment effective reducing appetite smoking ...   \n",
       "860   drug cleared skin even reduced redness scarrin...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "2686  real side effects unless consider lack fear wo...   \n",
       "1192   jittery sometimes euphoric tired cant sleep zone   \n",
       "2738                     redness dryness breakdown skin   \n",
       "2780  libido ever breasts hurt like got bigger itche...   \n",
       "1735  need take time went experienced augmentation r...   \n",
       "...                                                 ...   \n",
       "3092  felt slightly tired taking zyrtec however seve...   \n",
       "1095  nausea extreme sleepinesssevere headache jitte...   \n",
       "1130  dry mouth eyes drug decreased effectiveness la...   \n",
       "1294  began notice nothing seemed important also see...   \n",
       "860   severe sexual side effects began months trial ...   \n",
       "\n",
       "                                         commentsReview   Sales  Production  \\\n",
       "2686                                        taken daily  135166       335.0   \n",
       "1192  last results months adipex p lost pounds gaine...  739564       939.0   \n",
       "2738  topical compound used reduce hyperpigmentation...  683247       843.0   \n",
       "2780  given prevent pregnancy going i'd rather child...  222295       282.0   \n",
       "1735  took one milligram night treat symtoms restles...  344748       505.0   \n",
       "...                                                 ...     ...         ...   \n",
       "3092  non prescription drug took experiencing severe...  156028       356.0   \n",
       "1095  day one felt negative side effects taking seco...  317886       337.0   \n",
       "1130  prescribed mg per day taken much mg per day li...  556187       696.0   \n",
       "1294  taking bupropion aide break smoking habit also...  728338       789.0   \n",
       "860   treatment began two mg tablets twice day reduc...  154819       255.0   \n",
       "\n",
       "      benefitsReview_wc  sideEffectsReview_wc  commentsReview_wc  \n",
       "2686                 62                    15                  3  \n",
       "1192                163                    10                248  \n",
       "2738                  4                     5                 42  \n",
       "2780                 22                    50                 27  \n",
       "1735                 93                    69                106  \n",
       "...                 ...                   ...                ...  \n",
       "3092                 74                    54                 51  \n",
       "1095                  2                    10                120  \n",
       "1130                 15                    15                 24  \n",
       "1294                 44                   105                 92  \n",
       "860                  24                    70                145  \n",
       "\n",
       "[2485 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZe2wLAEkHaX",
    "outputId": "964a069f-c27f-4c27-b63b-d536511828c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real side effects unless consider lack fear worry one\n",
      "\n",
      "jittery sometimes euphoric tired cant sleep zone\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(train_set[\"sideEffectsReview\"][0:2].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8XHxHkmkHaX"
   },
   "source": [
    "Es hora de aplicar la \"capa\" de vectorizacion, pero keras sólo admite una entrada o feature por capa así que hay que crear tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "llNwo0MekHaX"
   },
   "outputs": [],
   "source": [
    "vectorizer_layers = []\n",
    "for indice,col in enumerate(text_feats):\n",
    "    vectorizer_layers.append(tf.keras.layers.TextVectorization(output_mode=\"count\"))\n",
    "    vectorizer_layers[indice].adapt(train_set[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPFlo99GkHaY"
   },
   "source": [
    "Y ahora creamos el modelo con la API funcional para intregarlo todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "x1zayCMXkHaY"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(43)\n",
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "# no le damos valor, pero aquí el argumento vocabulary permite pasar una lista,ç\n",
    "# una tupla, un array, un tensor con los strings ordenados de forma que el primero recibira la clase 0, etc\n",
    "ordinalEncoding_layers = [tf.keras.layers.StringLookup(output_mode=\"one_hot\") for cat in categoricals] \n",
    "                                                 \n",
    "\n",
    "# ordinalEncoding.adapt(train_set[categoricals]). Al igual que la capa de normalización hay que hacerle su fit en este caso el método adapt\n",
    "concat_layer = tf.keras.layers.Concatenate(axis = -1)\n",
    "hidden_layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "output_layer = tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "\n",
    "\n",
    "normalization_layer.adapt(train_set[numericas].to_numpy())\n",
    "_ = [ordinalEncoding_layers[indice].adapt(train_set[col]) for indice,col in enumerate(categoricals)]\n",
    "\n",
    "earlyS = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights= True)\n",
    "input_num = tf.keras.layers.Input(shape=(train_set[numericas].shape[1],))\n",
    "input_cats = [tf.keras.layers.Input(shape=(train_set[[col]].shape[1],), dtype = tf.string) for col in categoricals] # Importante decirle que entra una string\n",
    "\n",
    "# Añadimos las entradas para las capas de vectorizacion\n",
    "input_vects = [tf.keras.layers.Input(shape = train_set[col].shape[1:], dtype = tf.string) for col in text_feats]\n",
    "normalized = normalization_layer(input_num)\n",
    "encoded = [ordinalEncoding_layers[i](input_cats[i]) for i in range(len(ordinalEncoding_layers))]\n",
    "\n",
    "# Ahora vectorizamos\n",
    "vectorized = [vectorizer_layers[i](input_vects[i]) for i in range(len(text_feats))]\n",
    "concat = concat_layer([normalized] + encoded + vectorized)\n",
    "hidden1 = hidden_layer1(concat)\n",
    "output = output_layer(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_num] + input_cats + input_vects, outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNBxA7CPkHaY",
    "outputId": "891e6af4-af4e-4514-8e9c-8df26df0977b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.2587 - loss: 2.1173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - acc: 0.2642 - loss: 2.1027 - val_acc: 0.3863 - val_loss: 1.7189\n",
      "Epoch 2/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.4937 - loss: 1.3769 - val_acc: 0.4245 - val_loss: 1.5686\n",
      "Epoch 3/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.7274 - loss: 0.8940 - val_acc: 0.4346 - val_loss: 1.5979\n",
      "Epoch 4/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.8917 - loss: 0.5381 - val_acc: 0.4386 - val_loss: 1.7142\n",
      "Epoch 5/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9601 - loss: 0.3108 - val_acc: 0.4386 - val_loss: 1.7800\n",
      "Epoch 6/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9833 - loss: 0.1890 - val_acc: 0.4145 - val_loss: 1.7910\n",
      "Epoch 7/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9915 - loss: 0.1221 - val_acc: 0.4205 - val_loss: 1.7939\n",
      "Epoch 8/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9954 - loss: 0.0858 - val_acc: 0.4205 - val_loss: 1.8627\n",
      "Epoch 9/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9987 - loss: 0.0627 - val_acc: 0.4286 - val_loss: 1.9736\n",
      "Epoch 10/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9988 - loss: 0.0478 - val_acc: 0.4306 - val_loss: 2.0305\n",
      "Epoch 11/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0390 - val_acc: 0.4306 - val_loss: 2.0741\n",
      "Epoch 12/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0324 - val_acc: 0.4366 - val_loss: 2.1120\n",
      "Epoch 13/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0276 - val_acc: 0.4326 - val_loss: 2.1417\n",
      "Epoch 14/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0238 - val_acc: 0.4266 - val_loss: 2.1648\n",
      "Epoch 15/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 0.0208 - val_acc: 0.4266 - val_loss: 2.1826\n",
      "Epoch 16/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0184 - val_acc: 0.4286 - val_loss: 2.1986\n",
      "Epoch 17/150\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0164 - val_acc: 0.4306 - val_loss: 2.2142\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate= 2e-2, momentum = 0.9),\n",
    "              metrics =[\"acc\"])\n",
    "\n",
    "entradas = [train_set[numericas]] + [train_set[col] for col in categoricals] \\\n",
    "                + [train_set[col] for col in text_feats]               \n",
    "history = model.fit(entradas, y_num, validation_split=0.2, epochs=150, callbacks=earlyS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zl-a6g7ekHaY",
    "outputId": "e9207e7e-e550-4a47-dc30-0e918d60ef01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4150 - loss: 1.4902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5267363786697388, 0.41639870405197144]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_test = [test_set[numericas]] + [test_set[col] for col in test_set[categoricals]]\\\n",
    "                                         + [test_set[col] for col in text_feats]\n",
    "model.evaluate(entradas_test, test_set[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6y5oo1skHaY",
    "outputId": "415d79a7-e108-472a-c8c9-d1ee571bf1f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model.predict(entradas_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fO4JbVBkHaY",
    "outputId": "f75d013c-64ef-4665-ae00-007cff06a732",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71        62\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.50      0.09      0.15        23\n",
      "           3       0.50      0.06      0.10        18\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.27      0.08      0.12        38\n",
      "           6       0.17      0.07      0.10        83\n",
      "           7       0.26      0.66      0.37        94\n",
      "           8       0.36      0.04      0.07       110\n",
      "           9       0.57      0.84      0.68       151\n",
      "\n",
      "    accuracy                           0.42       622\n",
      "   macro avg       0.32      0.27      0.23       622\n",
      "weighted avg       0.37      0.42      0.33       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set[target], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G1iBImDkHaY"
   },
   "source": [
    "Desbalanceado y el recall medio cae. Además son demasiadas features. En la próxima sesión, de caracter teórico veremos una forma más potente de vectorizar texto y para terminar esta veamos como \"compensar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "-fMC1O_JkHaY",
    "outputId": "bfbe4a2b-2d75-45c4-82fb-06375626e2be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "9    0.237827\n",
       "7    0.186720\n",
       "8    0.148893\n",
       "6    0.107445\n",
       "0    0.097787\n",
       "4    0.053119\n",
       "2    0.049497\n",
       "5    0.047887\n",
       "3    0.035815\n",
       "1    0.035010\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_num.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FgBaz1gkHaZ",
    "outputId": "2f270e79-bf2a-4d5d-b0cf-ca3baf511778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases = np.array(sorted(y_num.unique()))\n",
    "clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeaIORnLkHaZ",
    "outputId": "aa0cf028-9a21-4178-a259-2113f7daf2eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.022633744855967,\n",
       " 1: 2.8563218390804597,\n",
       " 2: 2.0203252032520327,\n",
       " 3: 2.792134831460674,\n",
       " 4: 1.8825757575757576,\n",
       " 5: 2.088235294117647,\n",
       " 6: 0.9307116104868914,\n",
       " 7: 0.5355603448275862,\n",
       " 8: 0.6716216216216216,\n",
       " 9: 0.42047377326565144}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_weight = {clases[i]:peso for i,peso in enumerate(compute_class_weight(\"balanced\", classes= clases, y=y_num))}\n",
    "dict_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eeKrhelkHaZ",
    "outputId": "6c91a85c-3a39-4bca-fccd-ddba3508fc53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.6206 - loss: 1.3136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - acc: 0.6161 - loss: 1.3191 - val_acc: 0.3863 - val_loss: 1.8014\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8763 - loss: 0.4220 - val_acc: 0.4004 - val_loss: 2.4331\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9699 - loss: 0.1028 - val_acc: 0.4145 - val_loss: 2.5956\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9931 - loss: 0.0326 - val_acc: 0.3883 - val_loss: 2.7220\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9983 - loss: 0.0164 - val_acc: 0.3883 - val_loss: 2.9109\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9971 - loss: 0.0203 - val_acc: 0.4205 - val_loss: 2.8752\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0047 - val_acc: 0.4266 - val_loss: 2.8819\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0025 - val_acc: 0.4266 - val_loss: 2.9055\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0021 - val_acc: 0.4205 - val_loss: 2.9215\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0018 - val_acc: 0.4185 - val_loss: 2.9383\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1, momentum=0.9, nesterov=True),\n",
    "              metrics =[\"acc\"])\n",
    "\n",
    "history = model.fit(entradas, y_num.to_numpy(), validation_split=0.2, epochs=10, callbacks=earlyS, class_weight=dict_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fT_1R17akHaZ",
    "outputId": "94365d21-daeb-41dc-afc5-2b96ddfd1045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.4269 - loss: 1.6762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7642327547073364, 0.4003215432167053]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(entradas_test, test_set[target].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wz43AA8SkHaZ",
    "outputId": "5f4f6921-7cd8-4c27-980a-33c97e534e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lander\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_25', 'keras_tensor_26', 'keras_tensor_27', 'keras_tensor_28', 'keras_tensor_29', 'keras_tensor_30']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model.predict(entradas_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BG8cOjOdkHaZ",
    "outputId": "bc464af0-407e-4cdd-8cc2-37541fbb3b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68        62\n",
      "           1       0.38      0.19      0.25        16\n",
      "           2       0.22      0.22      0.22        23\n",
      "           3       0.08      0.11      0.10        18\n",
      "           4       0.11      0.44      0.18        27\n",
      "           5       0.31      0.29      0.30        38\n",
      "           6       0.17      0.06      0.09        83\n",
      "           7       0.32      0.41      0.36        94\n",
      "           8       0.42      0.10      0.16       110\n",
      "           9       0.64      0.78      0.71       151\n",
      "\n",
      "    accuracy                           0.40       622\n",
      "   macro avg       0.33      0.33      0.30       622\n",
      "weighted avg       0.41      0.40      0.38       622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_set[target], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNB3OX9CkHaZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
